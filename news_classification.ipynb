{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "news_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "9b91227945803d3a6cac5659d5abe05fddeabaf64f9016c8d20009a9e3e8cd53"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Parvez13/Adult_Income_Census_Prediction/blob/master/news_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ycMDVNMDdpe"
      },
      "source": [
        "# !pip install -U -q segmentation-models\n",
        "# !pip install -q tensorflow==2.5.0\n",
        "# !pip install -q keras==2.4.0\n",
        "# !pip install -q tensorflow-estimator==2.5.0"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C4zOwEPLaAF",
        "outputId": "b7f93605-739a-45e0-8bf9-2626cced911c"
      },
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import scipy\n",
        "import nltk\n",
        "import logging\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "## Imports libs\n",
        "import os\n",
        "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "# os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
        "# os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "\n",
        "from tensorflow import keras\n",
        "# import segmentation_models as sm\n"
      ],
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FYbXoLA8IQv2",
        "outputId": "06c13326-52ac-4ea0-80f0-2f45936271d2"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cf1jW_XPIVBH",
        "outputId": "45995dd2-d405-48ba-acbf-c66cef9bd054"
      },
      "source": [
        "keras.__version__"
      ],
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NagiR7L1LaAI"
      },
      "source": [
        "logging.basicConfig(filename='logs/logs.txt',\n",
        "                    filemode='a',\n",
        "                    format='%(asctime)s %(message)s',\n",
        "                    datefmt=\"%Y-%m-%d %H:%M:%S\")"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "i1kqKZzPLaAJ",
        "outputId": "a5127b59-f3b4-4b2d-fba0-22a500968469"
      },
      "source": [
        "#Logging\n",
        "logging.warning('Load Dataset')\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"BBC_News_Train.csv\")\n",
        "#df2 = pd.read_csv(\"Dataset/BBC_News_Test.csv\")\n",
        "\n",
        "# Check head\n",
        "logging.warning('Check Head')\n",
        "df.head()"
      ],
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleId</th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1833</td>\n",
              "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>154</td>\n",
              "      <td>german business confidence slides german busin...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1101</td>\n",
              "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1976</td>\n",
              "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>917</td>\n",
              "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ArticleId                                               Text  Category\n",
              "0       1833  worldcom ex-boss launches defence lawyers defe...  business\n",
              "1        154  german business confidence slides german busin...  business\n",
              "2       1101  bbc poll indicates economic gloom citizens in ...  business\n",
              "3       1976  lifestyle  governs mobile choice  faster  bett...      tech\n",
              "4        917  enron bosses in $168m payout eighteen former e...  business"
            ]
          },
          "metadata": {},
          "execution_count": 295
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4G9CyFdBLaAL",
        "outputId": "e160e7f5-3a78-4d25-e1a9-164363f57aef"
      },
      "source": [
        "# Check tail\n",
        "logging.warning('Check Tail')\n",
        "df.tail()"
      ],
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleId</th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1485</th>\n",
              "      <td>857</td>\n",
              "      <td>double eviction from big brother model caprice...</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1486</th>\n",
              "      <td>325</td>\n",
              "      <td>dj double act revamp chart show dj duo jk and ...</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1487</th>\n",
              "      <td>1590</td>\n",
              "      <td>weak dollar hits reuters revenues at media gro...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1488</th>\n",
              "      <td>1587</td>\n",
              "      <td>apple ipod family expands market apple has exp...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1489</th>\n",
              "      <td>538</td>\n",
              "      <td>santy worm makes unwelcome visit thousands of ...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      ArticleId  ...       Category\n",
              "1485        857  ...  entertainment\n",
              "1486        325  ...  entertainment\n",
              "1487       1590  ...       business\n",
              "1488       1587  ...           tech\n",
              "1489        538  ...           tech\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 296
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irfdIMysLaAM",
        "outputId": "a1d2c8ec-c217-4226-e360-60360a81ca83"
      },
      "source": [
        "# Info\n",
        "logging.warning('Info')\n",
        "df.info()"
      ],
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1490 entries, 0 to 1489\n",
            "Data columns (total 3 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   ArticleId  1490 non-null   int64 \n",
            " 1   Text       1490 non-null   object\n",
            " 2   Category   1490 non-null   object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 35.0+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "M3O5_1QQLaAM",
        "outputId": "aa901ddf-ca31-44f9-d3e2-f4447f92f486"
      },
      "source": [
        "# Describe\n",
        "logging.warning('Describe')\n",
        "df.describe()"
      ],
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleId</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1490.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>1119.696644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>641.826283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>565.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>1112.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1680.750000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2224.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         ArticleId\n",
              "count  1490.000000\n",
              "mean   1119.696644\n",
              "std     641.826283\n",
              "min       2.000000\n",
              "25%     565.250000\n",
              "50%    1112.500000\n",
              "75%    1680.750000\n",
              "max    2224.000000"
            ]
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OYG-jMa2LaAN",
        "outputId": "26a70a21-94bc-4d2e-f97b-9b7328e039dd"
      },
      "source": [
        "# Checking any null values\n",
        "logging.warning('Checking Null Values')\n",
        "df.isna().sum()"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ArticleId    0\n",
              "Text         0\n",
              "Category     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cY6KU-FELaAO",
        "outputId": "1fc9a165-ae7d-4b91-9c34-b369329bea37"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1490, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0nnJhi6JLaAP",
        "outputId": "f1be10f0-16f1-4308-bf50-a8fa48179fbb"
      },
      "source": [
        "# Value counts\n",
        "logging.warning('Check value counts for Category')\n",
        "df['Category'].value_counts()"
      ],
      "execution_count": 301,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sport            346\n",
              "business         336\n",
              "politics         274\n",
              "entertainment    273\n",
              "tech             261\n",
              "Name: Category, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 301
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffi_pyvCLaAQ"
      },
      "source": [
        "# Preprocessing\n",
        "logging.warning(\"-\"*100)\n",
        "logging.warning('Preprocessing')\n"
      ],
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "KXTor1u1LaAQ",
        "outputId": "49f9ec16-415e-4f8a-a673-86c8eeab0e8d"
      },
      "source": [
        "df"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleId</th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1833</td>\n",
              "      <td>worldcom ex-boss launches defence lawyers defe...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>154</td>\n",
              "      <td>german business confidence slides german busin...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1101</td>\n",
              "      <td>bbc poll indicates economic gloom citizens in ...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1976</td>\n",
              "      <td>lifestyle  governs mobile choice  faster  bett...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>917</td>\n",
              "      <td>enron bosses in $168m payout eighteen former e...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1485</th>\n",
              "      <td>857</td>\n",
              "      <td>double eviction from big brother model caprice...</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1486</th>\n",
              "      <td>325</td>\n",
              "      <td>dj double act revamp chart show dj duo jk and ...</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1487</th>\n",
              "      <td>1590</td>\n",
              "      <td>weak dollar hits reuters revenues at media gro...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1488</th>\n",
              "      <td>1587</td>\n",
              "      <td>apple ipod family expands market apple has exp...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1489</th>\n",
              "      <td>538</td>\n",
              "      <td>santy worm makes unwelcome visit thousands of ...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1490 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      ArticleId  ...       Category\n",
              "0          1833  ...       business\n",
              "1           154  ...       business\n",
              "2          1101  ...       business\n",
              "3          1976  ...           tech\n",
              "4           917  ...       business\n",
              "...         ...  ...            ...\n",
              "1485        857  ...  entertainment\n",
              "1486        325  ...  entertainment\n",
              "1487       1590  ...       business\n",
              "1488       1587  ...           tech\n",
              "1489        538  ...           tech\n",
              "\n",
              "[1490 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "87Ijz3odN-U5",
        "outputId": "e3ef5c3e-cd1a-4995-f96e-7fc4141f308b"
      },
      "source": [
        "df_shuffled = df.sample(frac=1,random_state=42)\n",
        "df_shuffled"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ArticleId</th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>2160</td>\n",
              "      <td>wal-mart is sued over rude lyrics the parents ...</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>1360</td>\n",
              "      <td>howard taunts blair over splits tony blair s f...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>302</td>\n",
              "      <td>fox attacks blair s tory  lies  tony blair lie...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>774</th>\n",
              "      <td>864</td>\n",
              "      <td>online commons to spark debate online communit...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>2184</td>\n",
              "      <td>piero gives rugby perspective bbc sport unveil...</td>\n",
              "      <td>tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1130</th>\n",
              "      <td>193</td>\n",
              "      <td>blair  said he would stand down  tony blair pr...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1294</th>\n",
              "      <td>111</td>\n",
              "      <td>us trade gap hits record in 2004 the gap betwe...</td>\n",
              "      <td>business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>833</td>\n",
              "      <td>tories pledge free sports lessons children wou...</td>\n",
              "      <td>politics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1459</th>\n",
              "      <td>2206</td>\n",
              "      <td>dance music not dead says fatboy dj norman coo...</td>\n",
              "      <td>entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1126</th>\n",
              "      <td>759</td>\n",
              "      <td>greek pair attend drugs hearing greek sprinter...</td>\n",
              "      <td>sport</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1490 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      ArticleId  ...       Category\n",
              "941        2160  ...  entertainment\n",
              "297        1360  ...       politics\n",
              "271         302  ...       politics\n",
              "774         864  ...           tech\n",
              "420        2184  ...           tech\n",
              "...         ...  ...            ...\n",
              "1130        193  ...       politics\n",
              "1294        111  ...       business\n",
              "860         833  ...       politics\n",
              "1459       2206  ...  entertainment\n",
              "1126        759  ...          sport\n",
              "\n",
              "[1490 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 304
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvr69tS_LaAR"
      },
      "source": [
        "# text\n",
        "text = df_shuffled['Text'].to_numpy()\n",
        "# Category\n",
        "category = df_shuffled['Category'].to_numpy()"
      ],
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4UE_DrWh5lp",
        "outputId": "46bbce80-a955-47ab-f5c6-28597bbc38ab"
      },
      "source": [
        "!pip install tensorflow_text"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.7.3)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: tensorflow<2.8,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.10.0.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.37.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (12.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.13.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.22.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.42.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8dlEHHSLaAR",
        "outputId": "60f9b99b-404b-4612-c474-a4df8505bf73"
      },
      "source": [
        "category"
      ],
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['entertainment', 'politics', 'politics', ..., 'politics',\n",
              "       'entertainment', 'sport'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm5P6HSUA_Mi"
      },
      "source": [
        "logging.warning(\"Labels One Hot\")"
      ],
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lLRAH_B8jGs",
        "outputId": "9085adbb-19d6-4605-a52f-e1d9c1ad8c4e"
      },
      "source": [
        "# One Hot encode labels\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot = OneHotEncoder(sparse=False)\n",
        "labels_one_hot = one_hot.fit_transform(category.reshape(-1,1))\n",
        "labels_one_hot"
      ],
      "execution_count": 314,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 314
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vo0UI-H0BE71"
      },
      "source": [
        "logging.warning(\"Labels encoded\")"
      ],
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pTgYi8F-YFX",
        "outputId": "1f31ca8a-e168-464c-f560-dd6b34cd9392"
      },
      "source": [
        "# Labels encode\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(category)\n",
        "labels_encoded[:20]"
      ],
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 2, 4, 4, 0, 4, 1, 0, 4, 2, 1, 0, 3, 4, 4, 0, 3, 2, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 316
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFDV7j1h-xz7",
        "outputId": "b548a740-d460-4a11-9dc0-b14248ff56c4"
      },
      "source": [
        "# Get class names and number of classes from labelencoder instance\n",
        "num_classes = len(label_encoder.classes_)\n",
        "class_names = label_encoder.classes_\n",
        "num_classes, class_names"
      ],
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, array(['business', 'entertainment', 'politics', 'sport', 'tech'],\n",
              "       dtype=object))"
            ]
          },
          "metadata": {},
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymrI6NhtLaAT"
      },
      "source": [
        "# replace category into numerical\n",
        "# df['Category'].replace({'sport':1,\n",
        "#                       'business':2,\n",
        "#                       'politics':3,\n",
        "#                       'entertainment':4,\n",
        "#                       'tech':5},\n",
        "#                      inplace=True,\n",
        "#                      regex=True)\n"
      ],
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPR3qlWdLaAU"
      },
      "source": [
        "# label = df['Category'].to_numpy()\n",
        "# label"
      ],
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBqDUj4vCZhY"
      },
      "source": [
        "logging.warning(\"-\"*100)\n",
        "logging.warning('Splitting')\n",
        "\n",
        "train_sentences,val_sentences,train_labels,val_labels = train_test_split(df_text,\n",
        "                                                                        labels_encoded,\n",
        "                                                                        random_state=42,\n",
        "                                                                        test_size=0.2)"
      ],
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uJj-mooO71I"
      },
      "source": [
        "logging.warning(\"-\"*100)"
      ],
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIR4aQ6YPIYZ",
        "outputId": "8658d8f5-bcce-48b5-b3b5-035ccac433fb"
      },
      "source": [
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": 322,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['faith schools citizenship warning schools must improve the quality of citizenship lessons - or social cohesion and democracy will suffer  says the education watchdog.  independent faith schools were singled out by ofsted chief  david bell  for not doing enough to promote the  wider tenets of british society . mr bell said muslim  jewish and evangelical christian schools must be  intolerant of intolerance . diversity  certainly must not mean segregated or separate   he said. mr bell s speech called for a much greater effort in all types of schools to teach citizenship - with an accompanying survey showing that young people knew little about politics and had no enthusiasm to find out more.  badly-taught citizenship lessons have previously been criticised by mr bell  and in a speech to the hansard society  he warned that it was failing to pass on an understanding of democracy  public service and shared values. he highlighted his particular concern for citizenship in the growing number of independent faith schools - which he said included about 100 muslim  100 evangelical christian and 50 jewish schools.  mr bell expressed concern about schools which did not teach children enough about a  common heritage  and needed to do more to promote principles of mutual tolerance and social inclusion.  i worry that many young people are being educated in faith-based schools  with little appreciation of their wider responsibilities and obligations to british society   said mr bell. the ofsted chief said his forthcoming annual report would make particular reference to muslim schools.  many must adapt their curriculum to ensure that it provides pupils with a broad general knowledge of public institutions and services in england and helps them to acquire an appreciation of and respect for other cultures in a way that promotes tolerance and harmony.  mr bell said such questions of religion and cultural identity were  tricky issues . but he argued that  we must not allow our recognition of diversity to become apathy in the face of any challenge to our coherence as a nation .  i would go further and say that an awareness of our common heritage as british citizens  equal under the law  should enable us to assert with confidence that we are intolerant of intolerance  illiberalism and attitudes and values that demean the place of certain sections of our community  be they women or people living in non-traditional relationships   said mr bell.',\n",
              "        'o sullivan quick to hail italians ireland coach eddie o sullivan heaped praise on italy after seeing his side stutter to a 28-17 victory in rome.   it was a hell of a tough game   said o sullivan.  we struggled in the first half because we hadn t the football.  italy played really well. they handled the ball well in terms of kicking it  if that s not an oxymoron.  we said before the game that it might take until 10 minutes from the end for this game to be won  and that s how it turned out.  ireland struggled to cope with italy s fierce start and were indebted to skipper brian o driscoll  who set up tries for geordan murphy and peter stringer.  we had our first attack in the italian half after 22 minutes   said o sullivan.  we had a good return  with three first-half possessions in their half and we scored twice.  the second half was about spending more time in their half.  scrum-half peter stringer was also glad that ireland escaped wtih a victory.  all credit to them   he told bbc sport.  we knew it would be tough coming to rome. they always give us a tough game here and they showed a lot of spirit.  they had a lot of ball in the first half but we got a few scores when we got into their 22.',\n",
              "        'christmas song formula  unveiled a formula for the ultimate christmas single has been revealed by chart bible british hit singles and albums.  the recipe includes a reference to father christmas  sleigh bells  a children s choir and a charity element. the song should also include christmas in the title  wishes for peace on earth and lots of airplay at office parties.  there are common musical elements linking nearly all the big christmas number ones of recent times   said editor david roberts. the book s analysts commissioned chart prank group moped to create the first christmas single using the whole formula - the song is called gonna have a no 1 this christmas by moped vs santa.   everybody says that christmas number ones are formulaic  but gonna have a number one this christmas is the first song to crack the formula and combine all these elements into one ultimate christmas track  said mr roberts.  surprisingly  there s no santa listed among the 8 000  top 75 chart performers in the book  so this is our chance to help santa to his rightful place in british recording history.  big festive hits over the years include band aid s do they know it s christmas   slade s merry christmas everybody  wham s last christmas and sir cliff richards  mistletoe and wine. band aid 20 s remake of do they know it s christmas is set to be confirmed as number one in the charts on sunday.',\n",
              "        'mps issued with blackberry threat mps will be thrown out of the commons if they use blackberries in the chamber speaker michael martin has ruled.  the £200 handheld computers can be used as a phone  pager or to send e-mails. the devices gained new prominence this week after alastair campbell used his to accidentally send an expletive-laden message to a newsnight journalist. mr martin revealed some mps had been using their blackberries during debates and he also cautioned members against using hidden earpieces.  the use of electronic devices in the commons chamber has long been frowned on. the sound of a mobile phone or a pager can result in a strong rebuke from either the speaker or his deputies. the speaker chairs debates in the commons and is charged with ensuring order in the chamber and enforcing rules and conventions of the house. he or she is always an mp chosen by colleagues who  once nominated  gives up all party political allegiances.',\n",
              "        'deal to ban  homophobic  reggae the reggae industry is to refuse to release or stage concerts featuring homophobic songs under a global deal struck with gay rights groups.  a damaging campaign against stars such as beenie man and sizzla has been waged over lyrics that allegedly call for gay people to be killed or assaulted. the campaign  which led to gigs being scrapped and a uk police investigation  will now be dropped under the truce. brett lock of gay group outrage! said they were  wiping the slate clean . the protests had been led by the stop murder music coalition  an umbrella group including outrage!  the black gay men s advisory group and jamaican movement j-flag.  that coalition has reached a verbal agreement with major dancehall reggae record labels and concert promoters covering eight of the scene s biggest stars. but the artists themselves were not involved in the negotiations and have not directly signed up. instead  the record companies have pledged not to release or re-release any offensive songs - many of which date back a number of years. and it is believed promoters will make stars agree not to perform such tunes on stage.  the reggae industry will work with the artists while still maintaining their freedom of speech and artistic freedom   according to media and pr strategist glen yearwood  who is representing the reggae industry.  the industry would halt any attempt by an artist to perform or release a song inciting violence against any group or gender  he said.  we ll advise them this is not the way forward in a civilised society.  the stop murder music campaign saw protesters picket gigs  resulted in sizzla s uk tour being cancelled in november  forced mobo award organisers to drop artists from nominations and saw beenie man dropped from an mtv show in august. police have also been investigating whether lyrics incite the assault and murder of gay people. the campaign was a blow to the reggae industry  mr yearwood admitted.  if you can t have major stars touring  then you don t sell many albums   he said.  but the artists - beenie man  sizzla  elephant man  buju banton  bounty killer  tok  capleton and vybz kartel - will not have to apologise for past songs or comments. outrage! s mr lock said:  the main players in the dancehall reggae industry will attempt to regulate the industry themselves to ensure that there aren t any violently homophobic or gay-bashing lyrics in the future.  as a gesture of good faith  the stop murder music coalition has agreed to suspend our aggressive campaigning against murder music.  so we shall not be picketing concerts or calling for prosecutions to give the industry the space to regulate and reform itself.  record companies vp and greensleeves  distributor jet star and concert promoters including jammins and apollo entertainment are all on board.',\n",
              "        'original exorcist to be screened the original version of horror prequel exorcist: the beginning  dropped by producers over claims it was not scary enough  is to have its world premiere.  the film  directed by paul schrader  will be screened on 18 march at the international festival of fantastic film in brussels. the psychological drama stars stellan skarsgard and foreruns the 1973 film. schrader was replaced by director renny harlin who made a new version of the film which debuted in 2004. the prequel project was originally announced in 2001  with actor liam neeson in the lead role and john frankenheimer as director. however frankenheimer pulled out in 2002  a month before he died.  skarsgard then replaced neeson in the role of father merrin  made famous by max von sydow in the 1973 film. principal footage was shot in morocco and rome at a reported cost of $32m. however  in august 2003 it emerged that producers morgan creek were shelving schrader s version of the film  having complained it was not scary enough. as well as replacing schrader with harlin - the director behind die hard 2 and cliffhanger - the producers also changed most of the cast  but swedish star skarsgard stayed in the merrin role. harlin s film  released in the uk in october 2004  received lukewarm reviews but went on to make over $76m (£40.7m) worldwide. the festival screening will be the first time that schrader s film has been seen in public. reports that it will be released either in cinemas or on dvd have yet to be confirmed. other films at the festival in the belgium capital  which runs from 11-26 march  include the us horror hit boogeyman and the forthcoming sequel ring 2  as well as a selection of films adapted from the works of jules verne.',\n",
              "        'mobile music challenges  ipod age  nokia and microsoft have agreed a deal to work on delivery of music to handsets  while sony ericsson has unveiled its phone walkman and motorola is working on an itunes phone.  can mobile phones replace the mp3 player in your pocket  the music download market has been growing steadily since record firms embraced digital distribution. ease of use  relative low price and increased access to broadband has helped drive the phenomenal growth of mp3 players.  full-length music downloads on mobile phones have not taken off so quickly - held back by technical challenges as well as issues over music availability. but the mobile music industry is confident that the days of dedicated mp3 players are numbered.  gilles babinet  chief executive of mobile music firm musiwave  said:  music downloads on mobiles have the potential to be the biggest-ever medium for music.   musiwave provides downloading infrastructure for the mobile phone market and mr babinet said the industry was enjoying  definite momentum.  but there are hurdles to overcome. mobile phones offer limited storage for music - certainly nothing to rival apple s 60gb ipod. but the first mobile phones with hard disk players will be on the market soon and the current generation of mobiles using flash technology can store up to one gigabyte of music - enough for 250 songs.  we are working in the hard disk area and we will be bringing out exciting devices   jonas guest  vice president for entertainment at nokia  told the bbc news website. but will mobiles become mere storage devices   one of the problems we could have is that mobiles are used just for storage and playback while pcs are used for downloading   said mr babinet   we don t want people to cast aside their pcs - we want mobile users to hook up into the existing ecosystems   explained mr guest.  you must enable people to transfer music from a pc to a handset and vice versa.   one of the key elements of the nokia and microsoft deal is the agreed ability to transfer songs between a handset and a pc. microsoft will adopt open standards allowing music to cross boundaries for the first time. songs can be downloaded on pc or mobile and transferred between the platforms.  the line between online and wireless is going to blur   predicted ted cohen  senior vice president of digital development and distribution at emi. he said:  the market is more regional in its maturity. in asia it is beyond belief.  the majority of our digital revenues in asia comes from mobiles. in north america it is fixed line while there is equilibrium in europe.   emi currently offers its entire 200 000 download catalogue for use by both by pcs and mobile phones. mr cohen said:  it s going to be just as important to connect through 3g or wireless as it is through your pc.  we want music to be a continuum.  the seamless experience of mobiles and pc downloads is approaching  he predicted. mr babinet said the mobile phone had a number of advantages over pcs which would see it become the focus for music downloading in the future.  getting music from your pc onto a device is not an easy experience. you have to switch the pc on  load the operating system  load the program  buy the music  download the music  and then transfer the music.  all of these steps can be done in one step on a mobile phone.  he said the mobile phone s billing system would make it easier for teenagers to embrace downloads  because pre-paid cards were already accepted by the age group.   certainly  we have a problem with battery  memory and bandwidth. but it s not about the current status. it s about the potential.  you will have all of your music on your mobile.  all three men said that the social interaction of mobile music would drive the market. mr cohen said:  i can send you the song and it is either billed to me or i send it to you and if you listen to it and want to keep  it is billed to you.  it s a social phenomenon.  mr babinet said:  today you use radio and tv to discover music. tomorrow you will discover and consume music via one device - the mobile.',\n",
              "        'dame julie pops in to see poppins mary poppins star dame julie andrews watched the hit stage version of her classic film at a charity performance in london s west end.  it was the first time dame julie  who shot to fame as the nanny in the 1964 disney movie  had seen the musical  staged at the prince edward theatre. she watched laura michelle kelly  23  reprise the role on stage. the show has been one of the west end s hottest tickets since opening in december  winning two olivier awards. kelly was named best musical actress at last month s ceremony and the musical also won best choreography.  but kelly said she was  very nervous  about meeting dame julie because she was  my absolute hero . the gala performance saw dame julie  69  return to the theatre where she had her first starring role in a performance of humpty dumpty in 1948. the mary poppins musical has been masterminded by theatre impresario sir cameron mackintosh and directed by richard eyre with choreography by matthew bourne. sir cameron said he hoped the production  which cost £9m to bring to the stage  was a blend of the sweet-natured film and the original book by pl travers. proceeds from thursday s show will go to charities including absolute return for kids (ark)  international relief agency operation usa and drama school lamda.',\n",
              "        'tech helps disabled speed demons an organisation has been launched to encourage disabled people to get involved in all aspects of motorsport  which is now increasingly possible thanks to technological innovations.  the motorsport endeavour club left the starting grid yesterday at the autosport international 2005 show at birmingham s nec  with several technologies to adapt vehicles on display.  motorcycle racer  roy tansley  from derby developed his electronic sequential gear changer following an accident which resulted in part of his left leg being amputated.  i needed to find a way of changing gear and generally you do that with your left leg   mr tansley told the bbc news website.  in simple terms  i needed to invent a left foot - initially it was quite a heath robinson device.  mr tansley had to argue his case to be allowed to continue competing with motorcycle racing s governing body  the autocycle union.  at that time they wouldn t let any amputee race at all  but eventually they told me i could have a licence as long as i raced sidecars.  mr tansley s invention  the pro-shift  is designed to work with hewland gearboxes which are widely used in motorcycle racing. in addition to helping disabled riders to compete  mr tansley reckons that the pro-shift saves at least 20 seconds per lap when he competes in the isle of man tt. as a result  there has been considerable interest in the product from other riders keen to improve their performance.  i m not prejudiced  i ll sell to able-bodied people if i have to!  he joked.  another exhibit on the motorsport endeavour stand is a subaru impreza rally car  adapted to accommodate a variety of disabilities. the vehicle belongs to pararallying  the world s only rally school for disabled drivers which is based in lincolnshire.   we use the latest technology supplied by an italian company   said rally driver dave hawkins who runs the company.  the cars have electronic throttles  electronic brakes  electronic clutches - we ve yet to turn anybody away.  mr hawkins - a paraplegic himself - says his customers have included right or left arm amputees  quadriplegics  people who have had strokes and a woman who had had all four limbs amputated. pararallying uses a vauxhall astra gsi with an automatic gearbox and manual subaru imprezas. the car on display is fitted with a  duck clutch  - a switch on the gear stick used instead of the clutch pedal. it also has a second ring behind the steering wheel to operate the throttle and a hand operated brake bar.  when joy rainey started competing in motorsport in 1974 she was continuing the family tradition - her father  murray  is a former australian formula 3 champion.  and it was rainey senior who modified a sports racer to accommodate his daughter s small stature so that she could take part in hill climbs. she uses an ordinary road car by putting extensions on the pedals  a cushion behind her back and raising the seat.  but in a competition car you have to have everything right or you ll lose the balance of the car   she said.  i bring everything back to me - steering wheel  steering column  gear lever and pedals.  when she recently took part in the london to sydney marathon she shared the driving with her partner  trevor  who now does the engineering work. he designed a system for their morris minor so that the adaptations could be totally removed in under a minute. the motorsport endeavour club is hoping that putting such technologies on display will result in more disabled people becoming involved in all areas of the sport and at every level.',\n",
              "        'collins appeals against drugs ban sprinter michelle collins has lodged an appeal against her eight-year doping ban with the north american court of arbitration for sport (cas).  the 33-year-old received the ban last month as a result of her connection to the federal inquiry into the balco doping scandal. she is the first athlete to be banned without a positive drugs test or an admission of drugs use. cas has said that a ruling is normally given within four months of an appeal. collins was suspended by the us anti-doping agency based on patterns observed in her blood and urine tests as well as evidence in the balco investigation. as well as being hit with the ban  collins was stripped of her 2003 world and us indoor 200m titles. the san francisco-based balco laboratory is at the centre of the scandal which has rocked the sport. the company has been accused of distributing illegal performance-enhancing drugs to elite athletes.'],\n",
              "       dtype=object), array([2, 3, 1, 2, 1, 1, 4, 1, 4, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 322
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TXnQgPIYtUO"
      },
      "source": [
        "train_sentences_r = tf.ragged.constant(train_sentences)\n",
        "val_sentences_r = tf.ragged.constant(val_sentences)"
      ],
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xj5-ZJSPBn8Y"
      },
      "source": [
        "logging.warning(\"Create a baseline model\")"
      ],
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIdi021bBiyR",
        "outputId": "0f34fc7b-680a-4208-a0ff-895084025ce1"
      },
      "source": [
        "# Create a baseline model\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(52)\n",
        "\n",
        "# Create a pipeline\n",
        "model_0 = Pipeline([\n",
        "    (\"tf-idf\", TfidfVectorizer()),\n",
        "    (\"clf\", MultinomialNB())\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences,train_labels)"
      ],
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('tf-idf', TfidfVectorizer()), ('clf', MultinomialNB())])"
            ]
          },
          "metadata": {},
          "execution_count": 325
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MclnfnvoBsDI",
        "outputId": "152595e9-3cb6-4409-9f48-4ce675e8d749"
      },
      "source": [
        "logging.warning(\"Evaluate baseline model\")\n",
        "model_0.score(val_sentences, val_labels)"
      ],
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9362416107382551"
            ]
          },
          "metadata": {},
          "execution_count": 326
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7LAvi9oBw-p"
      },
      "source": [
        "logging.warning(\"Make predictions\")"
      ],
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHkGQI-oB2qh",
        "outputId": "136d76db-6ed5-46d2-ae90-b22f49476741"
      },
      "source": [
        "# Make prediction\n",
        "baseline_predictions = model_0.predict(val_sentences)\n",
        "baseline_predictions"
      ],
      "execution_count": 328,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 3, 2, 2, 4, 4, 2, 3, 3, 1, 3, 3, 3, 3, 1, 2, 3, 0, 1, 3, 0,\n",
              "       0, 4, 3, 3, 1, 2, 3, 3, 2, 3, 1, 0, 0, 0, 2, 0, 0, 1, 3, 1, 4, 1,\n",
              "       4, 3, 3, 0, 3, 3, 0, 0, 0, 1, 3, 0, 3, 4, 2, 3, 3, 2, 0, 0, 4, 2,\n",
              "       4, 3, 2, 0, 2, 4, 3, 3, 4, 2, 3, 0, 1, 0, 3, 2, 0, 4, 2, 3, 0, 0,\n",
              "       0, 1, 3, 1, 3, 4, 4, 0, 4, 3, 2, 0, 0, 2, 3, 1, 1, 0, 2, 1, 1, 4,\n",
              "       3, 2, 3, 3, 4, 0, 1, 4, 0, 1, 4, 0, 0, 1, 1, 4, 3, 2, 3, 0, 2, 3,\n",
              "       3, 2, 2, 0, 4, 3, 4, 4, 3, 3, 4, 1, 4, 3, 3, 0, 3, 1, 3, 4, 3, 3,\n",
              "       1, 1, 0, 1, 2, 1, 1, 2, 3, 2, 0, 2, 4, 2, 0, 0, 2, 0, 3, 2, 4, 1,\n",
              "       0, 4, 0, 0, 4, 4, 4, 2, 2, 3, 4, 4, 4, 0, 1, 0, 2, 0, 1, 0, 0, 0,\n",
              "       2, 3, 0, 3, 2, 4, 0, 0, 4, 2, 0, 0, 3, 4, 2, 2, 3, 0, 0, 1, 4, 4,\n",
              "       0, 3, 1, 4, 1, 0, 3, 2, 2, 0, 4, 1, 2, 1, 4, 2, 3, 1, 2, 3, 0, 0,\n",
              "       3, 4, 3, 1, 4, 4, 3, 3, 3, 1, 4, 3, 1, 1, 4, 3, 0, 4, 0, 0, 2, 2,\n",
              "       0, 2, 2, 4, 0, 0, 3, 3, 4, 2, 3, 3, 4, 3, 0, 0, 2, 0, 0, 2, 0, 3,\n",
              "       1, 3, 1, 0, 3, 3, 2, 0, 0, 0, 4, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 328
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivCwKyVxLaAb",
        "outputId": "455c77e2-7d65-4f81-ec14-7f29a2ceeb86"
      },
      "source": [
        "sample_text = [\"Australia won the T20 Worldcup 2021 beating New Zealand by 8 wickets\"]\n",
        "model_0.predict(sample_text)"
      ],
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3])"
            ]
          },
          "metadata": {},
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "josANjdVLaAc",
        "outputId": "418f6e3c-edcb-4cbe-f2d6-3858689eda02"
      },
      "source": [
        "sample_text = [\"United States President Joe Biden and China’s President Xi Jinping on Tuesday agreed on the need to “responsibly” manage a competitive relationship but did not arrive at any significant breakthrough on any of the thorny issues that have led to increasingly confrontational ties.\"]\n",
        "model_0.predict(sample_text)"
      ],
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 330
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDwYZnm8LaAo",
        "outputId": "316a737f-1c0d-4b15-e121-0777212f9140"
      },
      "source": [
        "sample_text = [\"YSRCP party leading in the Nellor Elections\"]\n",
        "model_0.predict(sample_text)"
      ],
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2])"
            ]
          },
          "metadata": {},
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H03vAscLLaAn",
        "outputId": "d4584b52-9394-44e2-c588-3a5ac54fbadb"
      },
      "source": [
        "sample_text = [\"\"\"\n",
        "\"Support To Terrorists State Policy\": India Slams Pak At UN Over Kashmir\n",
        "\n",
        "\"\"\"]\n",
        "model_0.predict(sample_text)"
      ],
      "execution_count": 332,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {},
          "execution_count": 332
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4YotT1TLaAo",
        "outputId": "7249657b-36a6-4c41-9066-a711bd810518"
      },
      "source": [
        "sample_text = [\"Spider-Man No Way Home trailer: Tom Holland’s MCU film is the cinematic event of the year; meet Sinister Six\"]\n",
        "model_0.predict(sample_text)"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 333
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB5KOtW4LaAq",
        "outputId": "d1e7b6e8-2194-43b8-ee3b-7e3db5be33c7"
      },
      "source": [
        "sample_text = [\"Google: US technology giant to invest $740m in Australia\"]\n",
        "model_0.predict(sample_text)"
      ],
      "execution_count": 334,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4])"
            ]
          },
          "metadata": {},
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHOYxy-eO71L"
      },
      "source": [
        "# Function to evaluate: accuracy, precision, recall, f1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def evaluation_metrics(y_true, y_pred):\n",
        "    \n",
        "    \"\"\"\n",
        "    Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "    Args:\n",
        "    -----\n",
        "    y_true = true labels in the form of a 1D array\n",
        "    y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "    Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    # Calculate model accuracy\n",
        "    model_accuracy = accuracy_score(y_true,y_pred)\n",
        "    \n",
        "    # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "    model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "    model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "    return model_results"
      ],
      "execution_count": 335,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vN9qQZpO71L",
        "outputId": "6b244a38-0f7b-443d-897e-3f53c4d5df89"
      },
      "source": [
        "logging.warning(\"Evaluation metrics using baseline model \")\n",
        "baseline_results = evaluation_metrics(val_labels,baseline_predictions)\n",
        "baseline_results"
      ],
      "execution_count": 336,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9362416107382551,\n",
              " 'f1': 0.9355904724579887,\n",
              " 'precision': 0.940138821673615,\n",
              " 'recall': 0.9362416107382551}"
            ]
          },
          "metadata": {},
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzXYhYNBTu0L"
      },
      "source": [
        "# Preparing our data for deep sequence models"
      ],
      "execution_count": 337,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdfRPhTeTzeC",
        "outputId": "8e09af1a-f532-4c95-dd83-cfa944c25891"
      },
      "source": [
        "sent_lens = [len(sentence.split()) for sentence in train_sentences ]\n",
        "avg_sent_len = np.mean(sent_lens)\n",
        "avg_sent_len"
      ],
      "execution_count": 338,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "381.6090604026846"
            ]
          },
          "metadata": {},
          "execution_count": 338
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_Q7LzjULaAV",
        "outputId": "21e4e806-706c-4f54-8091-482317224902"
      },
      "source": [
        "logging.warning(\"-\"*100)\n",
        "logging.warning('Converting Text Into Numbers For Tokenization')\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# max_length\n",
        "max_length = round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))\n",
        "max_length"
      ],
      "execution_count": 339,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "382"
            ]
          },
          "metadata": {},
          "execution_count": 339
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "vSkYfLZfUGA3",
        "outputId": "5f41b6e9-94e0-4d83-fdf0-01fa50ce3891"
      },
      "source": [
        "plt.hist(sent_lens, bins=7);"
      ],
      "execution_count": 340,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KCFzjWWUaWe",
        "outputId": "2d4b68a4-ef22-439c-bbfa-6774cf538d46"
      },
      "source": [
        "# How long of sentence covers 95% of the lengths?\n",
        "output_seq_len = int(np.percentile(sent_lens, 95))\n",
        "output_seq_len"
      ],
      "execution_count": 341,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "714"
            ]
          },
          "metadata": {},
          "execution_count": 341
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLSgi56jUqMW",
        "outputId": "d558ecce-1256-4677-b1d5-39ae3816f40c"
      },
      "source": [
        "max(sent_lens)"
      ],
      "execution_count": 342,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3345"
            ]
          },
          "metadata": {},
          "execution_count": 342
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D61b1Ir5LaAV"
      },
      "source": [
        "max_tokens = 100000"
      ],
      "execution_count": 343,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9EAi6tYLaAW"
      },
      "source": [
        "text_vectorizer = TextVectorization(max_tokens=max_tokens,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=output_seq_len)"
      ],
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w-quV1ELaAW"
      },
      "source": [
        "text_vectorizer.adapt(train_sentences)\n"
      ],
      "execution_count": 345,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-N-xwpVLaAW",
        "outputId": "cc2c9e06-1371-4c4d-c9c2-24edd940db4b"
      },
      "source": [
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": 346,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 714), dtype=int64, numpy=\n",
              "array([[    1,     6, 20993,     7,   135,   668,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 346
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8y5ir5h7LaAW",
        "outputId": "677d7f5d-0b69-4d2a-9079-d2407e359218"
      },
      "source": [
        "# Choose a random sentence from the training dataset and tokenize it\n",
        "import random\n",
        "random_sentence = random.choice(train_sentences_r)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "b'jowell confirms casino climbdown tessa jowell has announced plans to limit the number of new casinos in the uk to 24  in a move branded a  humiliating retreat  by the tories.  it puts an end to plans for up to 40 super casinos  originally outlined in the government s gambling bill. instead there will be a cap of eight new casinos in each size category - small  medium and large. the culture secretary said the move showed she listened to critics who feared an explosion in gambling.  but conservative shadow culture secretary john whittingdale said the way the government had handled the bill was a  shambles .  this announcement is a further humiliating retreat by the government.  instead of the initial intention of the gambling bill  to liberalise the rules governing gambling  the bill now imposes a more restrictive regime than exists at present.  shares in british casino operators london clubs international  rank group and stanley leisure  who had been hoping the bill would pave the way for a big expansion in smaller casinos  fell by between 10 and 25% following the announcement. ms jowell s deputy  richard caborn  said the government had adopted a cautious approach to the issue  and responded to the concerns raised.  limiting the number of regional casinos to eight in the first phase is a cautious move that will allow us to test the impact of a new kind of casino on the levels of problem gambling   he said.  we also believe it s right to apply this same level of caution to small and large casinos.   he added that local authorities would still be able to stop new casinos coming to their areas. church groups welcomed the limit on the number of casinos. salvation army spokesman jonathan lomax said:  the proliferation of these casinos on high streets across the country was a real concern and the [three year] trial period  which we think should last at least five years  will enable research into the potentially severe social consequences of an increase in hard and addictive forms of gambling.  but british british casino association chairman penny cobham said her members were  outraged  by the decision  which followed a campaign in the daily mail newspaper.  there was never going to be a massive explosion of casinos. talk of a casino on every high street was just a scaring tactic.'      \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 714), dtype=int64, numpy=\n",
              "array([[ 3854,  7481,  3930, 22576,  7863,  3854,    20,   476,   179,\n",
              "            3,  1716,     2,   106,     4,    47,  3929,     7,     2,\n",
              "           73,     3,  1038,     7,     6,   267,  3937,     6, 13076,\n",
              "         6954,    24,     2,   415,    12,  3413,    33,   176,     3,\n",
              "          179,     9,    48,     3,   813,  1808,  3929,  1823,  4735,\n",
              "            7,     2,    72,     8,  3674,   384,   653,    52,    23,\n",
              "           17,     6,  2757,     4,   722,    47,  3929,     7,   400,\n",
              "         1446,  1353,   454,  4097,     5,   651,     2,  1651,   355,\n",
              "           14,     2,   267,   735,    76, 12741,     3,   839,    45,\n",
              "         5255,    33,  4827,     7,  3674,    25,   854,  1154,  1651,\n",
              "          355,   343, 15181,    14,     2,   116,     2,    72,    38,\n",
              "         5224,     2,   384,    15,     6,  9446,    35,  1473,    10,\n",
              "            6,   402, 13076,  6954,    24,     2,    72,   653,     4,\n",
              "            2,  2094,  3257,     4,     2,  3674,   384,     3,  9994,\n",
              "            2,   691,  2609,  3674,     2,   384,    70, 20052,     6,\n",
              "           42,  8047,  2814,    60,  7365,    22,  1302,   398,     7,\n",
              "          152,  3930,  1417,   189,  1688,   211,  4337,   170,     5,\n",
              "         4633,  8370,    45,    38,    40,  1118,     2,   384,    39,\n",
              "         8196,     2,   116,     9,     6,   214,  2000,     7,  1332,\n",
              "         3929,   704,    24,   157,   185,     5,   745,   393,     2,\n",
              "         1473,   421,  3854,     8,  1431,  1256, 22879,    14,     2,\n",
              "           72,    38,  3733,     6,  3927,  1271,     3,     2,   464,\n",
              "            5,  3063,     3,     2,   903,  1114,  6319,     2,   106,\n",
              "            4,  2373,  3929,     3,   722,     7,     2,    64,  7041,\n",
              "           10,     6,  3927,   267,    11,    23,   498,    49,     3,\n",
              "          657,     2,   943,     4,     6,    47,  1369,     4,  3930,\n",
              "           13,     2,   958,     4,   511,  3674,    16,    14,    34,\n",
              "           44,   385,    12,     8,   220,     3,  3955,    35,   291,\n",
              "          520,     4,  7534,     3,   454,     5,   651,  3929,    16,\n",
              "          118,    11,   408,   936,    39,   142,    17,   285,     3,\n",
              "          658,    47,  3929,   504,     3,    37,   859,  2753,   960,\n",
              "         2355,     2,  1716,    13,     2,   106,     4,  3929, 11868,\n",
              "         3953,   261,  1991, 19345,    14,     2,  9659,     4,   205,\n",
              "         3929,    13,   270,  2282,   488,     2,   166,    15,     6,\n",
              "          471,  1319,     5,     2,    98,    50,   689,   798,    36,\n",
              "           34,   171,   109,    66,    22,   571,   191,    81,    23,\n",
              "         3902,   344,    71,     2,  2574,  4030,  1178,  4497,     4,\n",
              "           33,   306,     7,   334,     5, 14493,  3678,     4,  3674,\n",
              "           25,   152,   152,  3930,   858,   634,  8186, 22545,    14,\n",
              "          100,   512,    43,  9775,    24,     2,   280,    36,  1102,\n",
              "            6,   271,     7,     2,  1465,  1455,   737,    52,    15,\n",
              "          394,   149,     3,    17,     6,  1137,  4827,     4,  3929,\n",
              "         1024,     4,     6,  3930,    13,   352,   270,   668,    15,\n",
              "           85,     6, 17025,  5489,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 347
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtFqsDwbVswH",
        "outputId": "4d0007c7-963d-4298-8d79-d42ccd74b903"
      },
      "source": [
        "vocab = text_vectorizer.get_vocabulary()\n",
        "len(vocab)"
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24905"
            ]
          },
          "metadata": {},
          "execution_count": 348
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpIivqA3LaAX"
      },
      "source": [
        "logging.warning('Embedding Layer')"
      ],
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvT05JW_LaAX",
        "outputId": "aad4c81b-0712-4a88-aaa4-d9655f913fa6"
      },
      "source": [
        "tf.random.set_seed(42)\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=len(vocab), # set input shape\n",
        "                             output_dim=128, # set size of embedding vector\n",
        "                             embeddings_initializer=\"uniform\", # default, intialize randomly\n",
        "                            # input_length=max_length, # how long is each input\n",
        "                             mask_zero=False,\n",
        "                             name=\"embedding_1\") \n",
        "\n",
        "embedding"
      ],
      "execution_count": 350,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7fd5fc028b50>"
            ]
          },
          "metadata": {},
          "execution_count": 350
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4pin9f8LaAY",
        "outputId": "ad2eff6b-2b41-41ba-cd10-5ecd4e14ba57"
      },
      "source": [
        "# Get a random sentence from training set\n",
        "import random\n",
        "random_sentence = random.choice(train_sentences_r)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nTokenization : \\n{text_vectorizer([random_sentence])}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": 351,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            "b'yukos accused of lying to court russian oil firm yukos lied to a us court in an attempt to stop the russian government selling off its key production unit  the court has heard.  the unit  yugansk  was sold to pay off a $27.5bn (\\xc2\\xa314.5bn) back tax bill. yukos argued that since it had a us subsidiary and local bank accounts  the us court could declare it bankrupt and stop the auction of yugansk. but deutsche bank - itself a target of a yukos lawsuit - said documents had been backdated to strengthen the case.  deutsche bank s evidence came on the first day of a two-day hearing in houston. its lawyer  hugh ray  told the court that yukos had claimed it had transferred $27m into two texas bank accounts opened by its new us subsidiary. by doing so  he said  the firm had intended to reinforce its us presence - and thus its chances of getting its case heard in us courts. but he said that the papers documenting the transaction were not drawn up till weeks after yukos made its bankruptcy application on 14 december  and then backdated.  yukos chief financial officer bruce misamore  who had moved to the us in early december to set up yukos usa  acknowledged the point. he said the discrepancy was only in the paperwork  but that money had indeed been transferred on 14 december. even so  he told the court that only $480 000 had been in the accounts that day  with the rest arriving a day later.  deutsche bank is involved in the case because it is itself being sued by yukos. it had agreed to loan to an arm of russian state gas firm gazprom the money to bid for yuganskneftegaz  as the yukos unit is formally known. the sale went ahead  despite an order from the us bankruptcy court ordered that it should be stopped. in the end  the auction was won by an unknown shell company for $9.4bn - much less than most assessments of its value - before ending up in the hands of state-controlled oil firm rosneft. rosneft  meanwhile  has agreed to merge with gazprom  bringing a large chunk of russia s very profitable oil business back under state control.  yukos maintains that it filed for bankruptcy in the us because it feared it would not be able to do so in russia. it also said that in the event of going bust  it could offer the chance of restructuring.  it gives us a kind of life after death alternative   said yukos chief executive steven theede. yukos is currently suing four companies - gazprom  its unit gazpromneft  rosneft and the shell company which won the bidding - for their part in yugansk s disposal. it has also threatened to sue the russian government for $28bn. analysts have questioned whether a us court has any jurisdiction over russian companies  while moscow officials have dismissed yukos  legal wrangling as meaningless. yukos claims that the rights of its shareholders have been ignored and that is has been punished for the political ambitions of its founder mikhail khodorkovsky. mr khodorkovsky  once russia s richest man  is in prison  having been charged with fraud and tax evasion and repeatedly denied bail.'      \n",
            "\n",
            "Tokenization : \n",
            "[[  499   829     4  3841     3   272   630   326   131   499  5175     3\n",
            "      6    49   272     7    33   907     3   658     2   630    72  1255\n",
            "    150    41   419   593  1000     2   272    20  1569     2  1000  2012\n",
            "     15   433     3   365   150     6  9032 11068   104   169   384   499\n",
            "   1087    11   140    12    38     6    49  3581     5   408   273  1274\n",
            "      2    49   272    57 10513    12  5372     5   658     2  1404     4\n",
            "   2012    25  1430   273   763     6  1002     4     6   499  1640    14\n",
            "   1891    38    40 14293     3  2918     2   361  1430   273     8   551\n",
            "    258    13     2    64   256     4     6  6019  1936     7  1830    41\n",
            "   1489  3657  1388    93     2   272    11   499    38   778    12    38\n",
            "   4605 24482    71    67  2129   273  1274  1556    24    41    47    49\n",
            "   3581    24   552    84    16    14     2   131    38  1932     3  6970\n",
            "     41    49  2823     5  5474    41  1612     4   490    41   361  1569\n",
            "      7    49  1496    25    16    14    11     2  1775 13634     2  5004\n",
            "     43    29  2328    48 11434   530    51   499    94    41  1016  3018\n",
            "     13   998   337     5   138 14293   499   209   331  1557  3145 12574\n",
            "     45    38  1164     3     2    49     7   279   337     3   108    48\n",
            "    499  2911  3160     2   440    16    14     2 21835    15    79     7\n",
            "      2  7069    25    11   221    38  2314    40  4605    13   998   337\n",
            "    180    84    16    93     2   272    11    79 24284   103    38    40\n",
            "      7     2  1274    11   256    18     2   922  6666     6   256   305\n",
            "   1430   273    10   751     7     2   361   113    12    10   763    97\n",
            "   3044    24   499    12    38   744     3  2709     3    33  2270     4\n",
            "    630   430  1833   131  1887     2   221     3   523     9  5418    19\n",
            "      2   499  1000    10  3885   632     2   356   308   442   268    33\n",
            "    591    27     2    49  1016   272  2580    11    12   109    17  1965\n",
            "      7     2   176     2  1404    15   133    24    33  3747  2676   141\n",
            "      9  9017   155   374    60   111 14336     4    41   842    92  4838\n",
            "     48     7     2  1192     4  7930   326   131  1972  1972   774    20\n",
            "    744     3  3446    18  1887  1657     6   651  5333     4   818     8\n",
            "     91  4062   326   229   104   173   430   340   499  7150    11    12\n",
            "   1461     9  1016     7     2    49   113    12  5255    12    39    29\n",
            "     17   285     3    90    84     7   818    12    44    14    11     7\n",
            "      2   532     4   149  6621    12    57   324     2   410     4  3398\n",
            "     12  1372    49     6  1369     4   317    51   852  2008    14   499\n",
            "    209   311  2021  9286   499    10   420  6060   206   238  1887    41\n",
            "   1000 13294  1972     5     2  2676   141    36   133     2  5365     9\n",
            "     37   163     7  2012     8  8693    12    20    44  2790     3  3045\n",
            "      2   630    72     9 24473   351    21  1710   389     6    49   272\n",
            "     20   107  4109    62   630   238   102  7117   887    21  2329   499\n",
            "    350 11118    19 12624   499   436    11     2   424     4    41  1179\n",
            "     21    40  3867     5    11    10    20    40  5096     9     2   472\n",
            "   2432     4    41  1723  3445  1929    30  1929   485   818     8  3394\n",
            "    426    10     7  1819   452    40  1541    18  1012     5   169  4832\n",
            "      5  4043   730  4223     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0     0     0     0     0     0     0\n",
            "      0     0     0     0     0     0]]      \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 714, 128), dtype=float32, numpy=\n",
              "array([[[ 0.04585798, -0.02728413, -0.01005446, ...,  0.03942828,\n",
              "         -0.01244868, -0.01237205],\n",
              "        [ 0.03719515, -0.00534731,  0.04295224, ..., -0.03597443,\n",
              "          0.02071606, -0.03299811],\n",
              "        [-0.04364428,  0.02437404, -0.03696011, ..., -0.04763393,\n",
              "          0.02931459,  0.0068561 ],\n",
              "        ...,\n",
              "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
              "          0.00912381, -0.00024097],\n",
              "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
              "          0.00912381, -0.00024097],\n",
              "        [ 0.01645621, -0.00589932, -0.01471175, ..., -0.02511839,\n",
              "          0.00912381, -0.00024097]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 351
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kat3Z7naO71N"
      },
      "source": [
        "logging.warning('Create Tensorboard Callback')\n",
        "import datetime\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "    \"\"\"\n",
        "    Creates a TensorBoard callback instand to store log files.\n",
        "    \n",
        "    Stores log files with the filepath:\n",
        "    \"dir_name/experiment_name/current_datetime/\"\n",
        "    \n",
        "    Args:\n",
        "      dir_name: target directory to store TensorBoard log files\n",
        "      experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
        "    \n",
        "    \"\"\"\n",
        "    \n",
        "    log_dir = dir_name + '/' + experiment_name + '/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir = log_dir\n",
        "    )\n",
        "    \n",
        "    print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "    return tensorboard_callback"
      ],
      "execution_count": 352,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5R3g26DO71N"
      },
      "source": [
        "logging.warning(\"Early Stopping Callbacks\")\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                          patience=3)"
      ],
      "execution_count": 353,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYmFD8hYLaAs"
      },
      "source": [
        "logging.warning(\"-\"*100)\n",
        "logging.warning(\"Simple Dense Model\")"
      ],
      "execution_count": 354,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-6npAuhE5-m"
      },
      "source": [
        "logging.warning(\"Create Dataset using `tf.data.Dataset` for training and validation\")"
      ],
      "execution_count": 355,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc-o12kHE-mO",
        "outputId": "ddecded6-ceec-4835-e682-3c11282f3480"
      },
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_sentences_r, train_labels))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_sentences_r, val_labels))\n",
        "\n",
        "train_dataset, val_dataset"
      ],
      "execution_count": 356,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.int64)>,\n",
              " <TensorSliceDataset shapes: ((), ()), types: (tf.string, tf.int64)>)"
            ]
          },
          "metadata": {},
          "execution_count": 356
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwxN9xjcFyyF",
        "outputId": "22f08a2c-3b30-4590-b197-89db95ff3e22"
      },
      "source": [
        "logging.warning(\"Prefetch batch using `tf.data.AUTOTUNE`\")\n",
        "train_dataset = train_dataset.batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "val_dataset =   val_dataset.batch(32).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "train_dataset, val_dataset"
      ],
      "execution_count": 357,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<PrefetchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int64)>,\n",
              " <PrefetchDataset shapes: ((None,), (None,)), types: (tf.string, tf.int64)>)"
            ]
          },
          "metadata": {},
          "execution_count": 357
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBhARMb4LaAs",
        "outputId": "e14160d9-18ef-44a7-ab1b-e9d58cbc7a38"
      },
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import  Dense, GlobalAveragePooling1D\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(452)\n",
        "\n",
        "# Construct model\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string,ragged=True) \n",
        "text_vectorization_layer = text_vectorizer(inputs) \n",
        "embedding_layer = embedding(text_vectorization_layer) \n",
        "global_average_pooling_layer = layers.GlobalAveragePooling1D()(embedding_layer) \n",
        "outputs = layers.Dense(num_classes, activation=\"softmax\")(global_average_pooling_layer) \n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")\n",
        "\n",
        "# Compile the model\n",
        "model_1.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "               optimizer=tf.keras.optimizers.Adam(),\n",
        "               metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "model_1.summary()"
      ],
      "execution_count": 358,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_2 (TextV  (None, 714)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 714, 128)          3187840   \n",
            "                                                                 \n",
            " global_average_pooling1d_11  (None, 128)              0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,188,485\n",
            "Trainable params: 3,188,485\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lG_RRZiLaAv"
      },
      "source": [
        "logging.warning(\"Fit and train model\")"
      ],
      "execution_count": 359,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKWEEn0wLaAw",
        "outputId": "cf806704-44bf-43ce-ce37-6b13f39193d9"
      },
      "source": [
        "# Fit\n",
        "history_1 = model_1.fit(train_dataset,\n",
        "                       epochs=5,\n",
        "                       validation_data=val_dataset,\n",
        "                       callbacks=[early_stopping_callback,\n",
        "                                 create_tensorboard_callback(dir_name='Model_logs',\n",
        "                                                            experiment_name='simple_dense_model')])"
      ],
      "execution_count": 360,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: Model_logs/simple_dense_model/20211128-031025\n",
            "Epoch 1/5\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 1.5906 - accuracy: 0.3909 - val_loss: 1.5601 - val_accuracy: 0.4631\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 1.5376 - accuracy: 0.4807 - val_loss: 1.4977 - val_accuracy: 0.5403\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 1.4691 - accuracy: 0.5386 - val_loss: 1.4164 - val_accuracy: 0.6577\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 1.3784 - accuracy: 0.6208 - val_loss: 1.3188 - val_accuracy: 0.7047\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 1.2688 - accuracy: 0.6946 - val_loss: 1.2117 - val_accuracy: 0.7383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7K_03XcjJcvu",
        "outputId": "3a9afc5a-f0d7-4d2b-f877-69d339c13c88"
      },
      "source": [
        "logging.warning(\"Evaluate model_1 on val_dataset\")\n",
        "model_1.evaluate(val_dataset)"
      ],
      "execution_count": 361,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 7ms/step - loss: 1.2117 - accuracy: 0.7383\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.2117449045181274, 0.7382550239562988]"
            ]
          },
          "metadata": {},
          "execution_count": 361
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xevXOH58LaAx"
      },
      "source": [
        "logging.warning(\"Make prediction using simple dense model\")"
      ],
      "execution_count": 362,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sSmUYHmlLaAx",
        "outputId": "765097b2-7a4f-49f9-fa5d-c8191484098d"
      },
      "source": [
        "model_1_pred_probs = model_1.predict(val_dataset)\n",
        "model_1_pred_probs\n"
      ],
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.23281929, 0.29177478, 0.1147351 , 0.2842985 , 0.0763724 ],\n",
              "       [0.21276124, 0.3368662 , 0.12615632, 0.23565072, 0.08856554],\n",
              "       [0.2363207 , 0.23289981, 0.11154401, 0.3508876 , 0.06834788],\n",
              "       ...,\n",
              "       [0.32061094, 0.15247129, 0.17423536, 0.18107481, 0.17160766],\n",
              "       [0.14969335, 0.07568391, 0.21736792, 0.08588349, 0.47137126],\n",
              "       [0.17812768, 0.14570095, 0.33635208, 0.18901469, 0.15080465]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 363
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5fqURVsJjwY",
        "outputId": "d887de05-d3fe-478f-bea1-ff5fb4720bbf"
      },
      "source": [
        "model_1_preds = tf.argmax(model_1_pred_probs,axis=1)\n",
        "model_1_preds"
      ],
      "execution_count": 364,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(298,), dtype=int64, numpy=\n",
              "array([1, 1, 3, 3, 2, 4, 4, 3, 3, 3, 3, 3, 3, 3, 4, 1, 2, 3, 0, 3, 3, 0,\n",
              "       0, 4, 3, 3, 3, 2, 3, 3, 2, 3, 3, 0, 0, 0, 2, 0, 0, 3, 3, 3, 4, 3,\n",
              "       4, 3, 3, 0, 3, 3, 0, 0, 0, 3, 3, 0, 3, 4, 2, 3, 3, 2, 0, 0, 0, 2,\n",
              "       4, 3, 2, 0, 2, 4, 3, 3, 0, 2, 3, 0, 3, 0, 3, 2, 0, 0, 3, 3, 0, 0,\n",
              "       0, 4, 3, 1, 3, 4, 4, 0, 3, 3, 2, 2, 0, 2, 3, 3, 1, 0, 2, 4, 3, 0,\n",
              "       3, 2, 3, 3, 0, 0, 3, 4, 0, 1, 4, 0, 0, 3, 0, 4, 3, 2, 3, 0, 2, 3,\n",
              "       3, 0, 3, 4, 4, 3, 0, 0, 3, 3, 4, 3, 0, 3, 3, 0, 0, 3, 3, 0, 3, 3,\n",
              "       1, 3, 0, 3, 2, 3, 3, 2, 3, 3, 0, 3, 4, 2, 0, 4, 2, 0, 3, 2, 4, 0,\n",
              "       0, 4, 0, 0, 4, 4, 4, 3, 2, 3, 0, 4, 4, 0, 3, 0, 2, 0, 0, 0, 0, 0,\n",
              "       2, 4, 0, 3, 3, 4, 0, 0, 4, 3, 0, 0, 3, 4, 2, 2, 3, 0, 0, 3, 4, 4,\n",
              "       0, 3, 3, 4, 3, 0, 3, 3, 2, 0, 4, 3, 2, 4, 4, 2, 4, 3, 2, 3, 0, 0,\n",
              "       3, 4, 3, 0, 4, 0, 3, 3, 4, 1, 4, 3, 3, 3, 4, 3, 0, 4, 0, 0, 4, 0,\n",
              "       0, 2, 2, 4, 0, 0, 3, 2, 4, 0, 3, 3, 0, 3, 0, 0, 2, 0, 0, 2, 0, 3,\n",
              "       1, 3, 3, 0, 3, 3, 0, 3, 0, 0, 4, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 364
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irOu28IbLaAy"
      },
      "source": [
        "logging.warning(\"Evaluate using simple dense model\")"
      ],
      "execution_count": 365,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbcrrcbbLaAz",
        "outputId": "c1cc6bc8-5dbb-44bf-b920-802105d63f24"
      },
      "source": [
        "# Calculate model_1 metrics\n",
        "model_1_results = evaluation_metrics(y_true=val_labels, \n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": 366,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.738255033557047,\n",
              " 'f1': 0.7031040637698016,\n",
              " 'precision': 0.803971563751046,\n",
              " 'recall': 0.738255033557047}"
            ]
          },
          "metadata": {},
          "execution_count": 366
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IkWN1F6iLaAz"
      },
      "source": [
        "logging.warning(\"-\"*100)\n",
        "logging.warning(\"Model 2 Conv1D\")"
      ],
      "execution_count": 367,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1X-ix93_Pr-f",
        "outputId": "e215636d-cc43-48b7-aada-1278d5483484"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "# Create Conv1D model\n",
        "inputs = layers.Input(shape=(1,),dtype='string',ragged=True)\n",
        "text_vectorization_layer = text_vectorizer(inputs)\n",
        "embedding_layer = embedding(text_vectorization_layer)\n",
        "x = layers.Conv1D(64, 5, padding='same', activation='relu')(embedding_layer)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(5, activation='softmax')(x)\n",
        "model_2 = tf.keras.Model(inputs,outputs,name='model_2_Conv1D')\n",
        "\n",
        "# Compile\n",
        "model_2.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# summary \n",
        "model_2.summary()"
      ],
      "execution_count": 368,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_Conv1D\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_2 (TextV  (None, 714)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 714, 128)          3187840   \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 714, 64)           41024     \n",
            "                                                                 \n",
            " global_average_pooling1d_12  (None, 64)               0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,229,189\n",
            "Trainable params: 3,229,189\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xog6I1rSFic5"
      },
      "source": [
        "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "# if len(physical_devices) > 0:\n",
        "#    tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ],
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MjSXybDTRqcd",
        "outputId": "e878c3ae-7c21-43d3-b523-2278d008f849"
      },
      "source": [
        "logging.warning(\"Fit and train model\")\n",
        "history_2 = model_2.fit(train_dataset,\n",
        "                        epochs=5,\n",
        "                        validation_data=val_dataset,\n",
        "                        callbacks=[early_stopping_callback,\n",
        "                                 create_tensorboard_callback(dir_name='Model_logs',\n",
        "                                                            experiment_name='model_2_Conv1d')])"
      ],
      "execution_count": 370,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: Model_logs/model_2_Conv1d/20211128-031031\n",
            "Epoch 1/5\n",
            "38/38 [==============================] - 2s 31ms/step - loss: 1.2857 - accuracy: 0.7064 - val_loss: 1.0097 - val_accuracy: 0.7349\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.7457 - accuracy: 0.8591 - val_loss: 0.6198 - val_accuracy: 0.8926\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.3980 - accuracy: 0.9480 - val_loss: 0.3816 - val_accuracy: 0.9262\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2078 - accuracy: 0.9815 - val_loss: 0.2540 - val_accuracy: 0.9497\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.1168 - accuracy: 0.9916 - val_loss: 0.1903 - val_accuracy: 0.9564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rFQNuidSOi4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42c42070-b085-4284-d613-81a6c68c5c29"
      },
      "source": [
        "logging.warning(\"Evaluate using model_2 on val_dataset\")\n",
        "model_2.evaluate(val_dataset)"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 9ms/step - loss: 0.1903 - accuracy: 0.9564\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19032272696495056, 0.9563758373260498]"
            ]
          },
          "metadata": {},
          "execution_count": 371
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gtn-iENXK6IT"
      },
      "source": [
        "logging.warning(\"Make prediction with Conv1D model\")"
      ],
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8toTgtkLA0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3095417-9774-4143-fb73-e7be253e1eb8"
      },
      "source": [
        "model_2_pred_probs = model_2.predict(val_dataset)\n",
        "model_2_pred_probs"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.9423042e-03, 9.5494246e-01, 9.2833936e-03, 2.0699628e-02,\n",
              "        9.1321766e-03],\n",
              "       [1.4363864e-04, 9.9755341e-01, 8.0338184e-04, 1.9063900e-04,\n",
              "        1.3089109e-03],\n",
              "       [2.0791017e-02, 7.3765099e-02, 2.6468655e-02, 8.7059158e-01,\n",
              "        8.3836867e-03],\n",
              "       ...,\n",
              "       [9.8919654e-01, 5.9856719e-04, 3.9441199e-03, 1.3854157e-04,\n",
              "        6.1222413e-03],\n",
              "       [9.7913481e-04, 7.0150703e-04, 2.5562788e-04, 8.1528361e-07,\n",
              "        9.9806291e-01],\n",
              "       [2.1310350e-04, 6.3758617e-04, 9.9895418e-01, 1.0040898e-04,\n",
              "        9.4655778e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 373
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImZ0xvYWLKFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96404912-e99f-460e-fe21-8259f77e0882"
      },
      "source": [
        "model_2_preds = tf.argmax(model_2_pred_probs, axis=1)\n",
        "model_2_preds"
      ],
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(298,), dtype=int64, numpy=\n",
              "array([1, 1, 3, 2, 2, 4, 4, 2, 3, 3, 1, 3, 3, 3, 1, 1, 2, 3, 0, 1, 3, 0,\n",
              "       0, 4, 3, 3, 1, 2, 3, 3, 2, 3, 1, 0, 0, 0, 2, 0, 0, 1, 3, 1, 4, 1,\n",
              "       4, 3, 3, 0, 3, 3, 0, 0, 0, 1, 3, 0, 3, 4, 2, 3, 3, 2, 0, 0, 4, 2,\n",
              "       4, 3, 2, 0, 2, 4, 3, 3, 4, 2, 1, 0, 1, 0, 3, 2, 0, 4, 2, 3, 0, 0,\n",
              "       0, 1, 1, 1, 3, 4, 4, 0, 4, 3, 2, 0, 0, 2, 3, 1, 1, 0, 2, 1, 1, 4,\n",
              "       3, 2, 3, 3, 0, 0, 1, 4, 0, 1, 4, 0, 0, 1, 1, 4, 3, 2, 3, 0, 2, 3,\n",
              "       3, 2, 2, 0, 4, 3, 4, 4, 3, 3, 4, 1, 4, 1, 3, 0, 0, 1, 3, 4, 3, 3,\n",
              "       1, 1, 0, 1, 2, 1, 1, 2, 3, 1, 0, 2, 4, 2, 0, 4, 2, 0, 3, 2, 4, 1,\n",
              "       0, 4, 0, 0, 4, 4, 4, 2, 2, 3, 4, 4, 4, 0, 1, 0, 2, 0, 1, 0, 0, 0,\n",
              "       2, 3, 0, 3, 2, 4, 0, 0, 4, 1, 0, 0, 3, 4, 2, 2, 3, 0, 0, 1, 4, 4,\n",
              "       0, 3, 1, 4, 1, 0, 3, 2, 2, 0, 4, 1, 2, 4, 4, 2, 4, 1, 2, 3, 0, 0,\n",
              "       3, 4, 3, 1, 4, 4, 3, 3, 3, 1, 4, 3, 1, 1, 4, 3, 0, 4, 0, 0, 2, 2,\n",
              "       0, 2, 2, 4, 0, 0, 3, 2, 4, 2, 3, 3, 4, 3, 0, 0, 2, 0, 0, 2, 0, 3,\n",
              "       1, 3, 1, 0, 3, 3, 2, 0, 0, 0, 4, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 374
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0f9_Al4OLRxr"
      },
      "source": [
        "logging.warning(\"Evaluation metrics using Conv1D\")\n"
      ],
      "execution_count": 375,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPtFYwkQLbjL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "765ecfcc-f4f7-439f-df30-69005642a9ec"
      },
      "source": [
        "model_2_results = evaluation_metrics(val_labels,\n",
        "                                     model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9563758389261745,\n",
              " 'f1': 0.9560226495196614,\n",
              " 'precision': 0.9571000659771737,\n",
              " 'recall': 0.9563758389261745}"
            ]
          },
          "metadata": {},
          "execution_count": 376
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHprM20xLqkS"
      },
      "source": [
        "logging.warning(\"-\"*100)\n",
        "logging.warning(\"Model_3 LSTM\")"
      ],
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM2R9hGaMIer",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1c85ee9-2432-419b-c79f-c435d8c271e5"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "# Build LSTM model\n",
        "inputs = tf.keras.Input(shape=(1,),dtype=tf.string,ragged=True)\n",
        "text_vectorization_layer = text_vectorizer(inputs)\n",
        "embedding_layer = embedding(text_vectorization_layer)\n",
        "x = layers.LSTM(64,return_sequences=True)(embedding_layer)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs,name='Model_3_LSTM')\n",
        "\n",
        "# Compile\n",
        "model_3.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "model_3.summary()"
      ],
      "execution_count": 378,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Model_3_LSTM\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_14 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_2 (TextV  (None, 714)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 714, 128)          3187840   \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 714, 64)           49408     \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 714, 128)          8320      \n",
            "                                                                 \n",
            " global_average_pooling1d_13  (None, 128)              0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,246,213\n",
            "Trainable params: 3,246,213\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AFpeGQDNvxR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31ef244d-cabf-4e68-c6fc-8f6c57b9400a"
      },
      "source": [
        "logging.warning(\"Fit and train model\")\n",
        "history_3 = model_3.fit(train_dataset,\n",
        "                        epochs=5,\n",
        "                        validation_data=val_dataset,\n",
        "                        callbacks=[early_stopping_callback,\n",
        "                                   create_tensorboard_callback(dir_name='Model_logs',\n",
        "                                                               experiment_name='Model_3_LSTM')])"
      ],
      "execution_count": 379,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: Model_logs/Model_3_LSTM/20211128-031037\n",
            "Epoch 1/5\n",
            "38/38 [==============================] - 9s 165ms/step - loss: 1.1725 - accuracy: 0.6133 - val_loss: 0.7420 - val_accuracy: 0.7987\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 5s 144ms/step - loss: 0.3463 - accuracy: 0.9362 - val_loss: 0.3425 - val_accuracy: 0.9329\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 5s 142ms/step - loss: 0.1567 - accuracy: 0.9757 - val_loss: 0.6285 - val_accuracy: 0.8624\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 5s 136ms/step - loss: 0.4572 - accuracy: 0.8683 - val_loss: 0.3544 - val_accuracy: 0.8993\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 5s 137ms/step - loss: 0.1611 - accuracy: 0.9740 - val_loss: 0.1923 - val_accuracy: 0.9497\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB8QryeXPYz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7df1387d-6380-449f-d595-b0f448d0048e"
      },
      "source": [
        "logging.warning(\"Evaluate model_3 on val_dataset\")\n",
        "model_3.evaluate(val_dataset)"
      ],
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 50ms/step - loss: 0.1923 - accuracy: 0.9497\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19225403666496277, 0.9496644139289856]"
            ]
          },
          "metadata": {},
          "execution_count": 380
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0Bpyt7rQNmP"
      },
      "source": [
        "logging.warning(\"Make prediction with LSTM model\")"
      ],
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOQrSI16QUCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4bedfb7-e759-4c42-896b-a6beae3b0549"
      },
      "source": [
        "model_3_pred_probs = model_3.predict(val_dataset)\n",
        "model_3_pred_probs"
      ],
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.1942911e-03, 9.4949746e-01, 3.9439775e-02, 1.2104592e-03,\n",
              "        6.6579762e-03],\n",
              "       [4.5058655e-04, 9.8110813e-01, 1.6278021e-02, 1.1361423e-04,\n",
              "        2.0495879e-03],\n",
              "       [4.1668206e-02, 3.4237493e-02, 2.0604704e-02, 8.9223111e-01,\n",
              "        1.1258488e-02],\n",
              "       ...,\n",
              "       [9.9321234e-01, 2.2478173e-04, 4.7771949e-03, 5.4499391e-04,\n",
              "        1.2407548e-03],\n",
              "       [2.5747376e-03, 2.4871699e-06, 3.2705378e-03, 1.6430977e-06,\n",
              "        9.9415058e-01],\n",
              "       [7.7727792e-04, 4.7511216e-03, 9.8991287e-01, 5.2866588e-05,\n",
              "        4.5058383e-03]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 382
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgGy08o8QY-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c27762f-bff4-4b82-9586-2e9d6b9a9a07"
      },
      "source": [
        "model_3_preds = tf.argmax(model_3_pred_probs, axis=1)\n",
        "model_3_preds"
      ],
      "execution_count": 383,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(298,), dtype=int64, numpy=\n",
              "array([1, 1, 3, 2, 2, 4, 4, 2, 3, 3, 1, 3, 3, 3, 3, 1, 2, 3, 0, 1, 3, 0,\n",
              "       0, 4, 3, 3, 1, 2, 3, 3, 2, 3, 1, 0, 0, 0, 2, 0, 0, 1, 3, 1, 4, 1,\n",
              "       4, 3, 3, 0, 3, 3, 0, 0, 0, 1, 3, 0, 3, 4, 2, 3, 3, 2, 4, 4, 4, 2,\n",
              "       4, 3, 2, 0, 2, 4, 3, 3, 4, 2, 1, 0, 1, 0, 3, 2, 0, 4, 2, 3, 0, 0,\n",
              "       0, 1, 2, 1, 3, 4, 4, 0, 4, 3, 2, 0, 0, 2, 3, 1, 1, 0, 2, 1, 1, 4,\n",
              "       3, 2, 3, 3, 4, 4, 1, 4, 4, 1, 4, 0, 0, 1, 1, 4, 3, 2, 3, 0, 2, 3,\n",
              "       3, 4, 2, 0, 4, 3, 4, 4, 3, 3, 4, 1, 4, 1, 3, 0, 0, 1, 3, 4, 3, 3,\n",
              "       1, 1, 0, 1, 2, 1, 1, 2, 3, 1, 0, 2, 4, 2, 0, 4, 2, 0, 3, 2, 4, 1,\n",
              "       0, 4, 0, 0, 4, 4, 4, 2, 2, 3, 4, 4, 4, 0, 1, 4, 2, 0, 1, 0, 0, 0,\n",
              "       2, 3, 4, 3, 2, 4, 0, 0, 4, 1, 0, 0, 3, 4, 2, 2, 3, 4, 0, 1, 4, 4,\n",
              "       0, 3, 1, 4, 1, 0, 3, 2, 2, 0, 4, 1, 2, 1, 4, 2, 2, 1, 2, 3, 0, 0,\n",
              "       3, 4, 3, 1, 4, 4, 3, 3, 3, 1, 4, 3, 1, 1, 4, 3, 0, 4, 4, 0, 2, 2,\n",
              "       0, 2, 2, 4, 0, 4, 3, 1, 4, 2, 3, 3, 4, 3, 0, 0, 2, 0, 2, 2, 0, 3,\n",
              "       1, 3, 1, 0, 3, 3, 2, 0, 0, 0, 4, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 383
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgf2Shy_QetH"
      },
      "source": [
        "logging.warning(\"Evaluation metrics using LSTM\")"
      ],
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRjM3XTbQjG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e21dd149-0361-4a2a-e774-48f42addbec3"
      },
      "source": [
        "model_3_results = evaluation_metrics(val_labels,\n",
        "                                     model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": 385,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9496644295302014,\n",
              " 'f1': 0.9497006912144507,\n",
              " 'precision': 0.9523289639810494,\n",
              " 'recall': 0.9496644295302014}"
            ]
          },
          "metadata": {},
          "execution_count": 385
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fynx3jbIQodf"
      },
      "source": [
        "logging.warning(\"-\"*100)\n",
        "logging.warning(\"Model 4 GRU\")\n"
      ],
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vcntDHoQd0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdbeded2-4397-43cd-fc10-0676517330a2"
      },
      "source": [
        "#  Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "\n",
        "# Build model\n",
        "inputs = tf.keras.Input(shape=(1,),dtype=tf.string,ragged=True)\n",
        "text_vectorization_layer = text_vectorizer(inputs)\n",
        "embedding_layer = embedding(text_vectorization_layer)\n",
        "x = layers.GRU(64, return_sequences=True)(embedding_layer)\n",
        "x = layers.Dense(128,activation='relu')(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "model_4 = tf.keras.Model(inputs,outputs,name='model_4_GRU')\n",
        "\n",
        "# Compile\n",
        "model_4.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "model_4.summary()"
      ],
      "execution_count": 387,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_2 (TextV  (None, 714)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 714, 128)          3187840   \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 714, 64)           37248     \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 714, 128)          8320      \n",
            "                                                                 \n",
            " global_average_pooling1d_14  (None, 128)              0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,234,053\n",
            "Trainable params: 3,234,053\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIUKzoxGSXZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2f065e2-b050-4fa4-c71e-e4de0061a4f7"
      },
      "source": [
        "logging.warning(\"Fit and train model\")\n",
        "history_4 = model_4.fit(train_dataset,\n",
        "                        epochs=5,\n",
        "                        validation_data=val_dataset,\n",
        "                        callbacks=[early_stopping_callback,\n",
        "                                   create_tensorboard_callback('Model_logs',\n",
        "                                                               'Model_4_GRU')])"
      ],
      "execution_count": 388,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: Model_logs/Model_4_GRU/20211128-031123\n",
            "Epoch 1/5\n",
            "38/38 [==============================] - 9s 165ms/step - loss: 1.2982 - accuracy: 0.5906 - val_loss: 0.7931 - val_accuracy: 0.7517\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 6s 150ms/step - loss: 0.3655 - accuracy: 0.9245 - val_loss: 0.2509 - val_accuracy: 0.9262\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 6s 150ms/step - loss: 0.0726 - accuracy: 0.9941 - val_loss: 0.2261 - val_accuracy: 0.9530\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 6s 149ms/step - loss: 0.0328 - accuracy: 0.9950 - val_loss: 0.2592 - val_accuracy: 0.9362\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 6s 150ms/step - loss: 0.0478 - accuracy: 0.9908 - val_loss: 0.1140 - val_accuracy: 0.9664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDiCb4f6Spv7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae97901-4e73-4ff4-f367-3a596fd1baf5"
      },
      "source": [
        "logging.warning(\"Evaluate Model 4 on val_dataset\")\n",
        "model_4.evaluate(val_dataset)"
      ],
      "execution_count": 389,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1140 - accuracy: 0.9664\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.11397363245487213, 0.9664429426193237]"
            ]
          },
          "metadata": {},
          "execution_count": 389
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_tycQ1tTJjt"
      },
      "source": [
        "logging.warning(\"Make Prediction using model_4 on val_dataset\")\n"
      ],
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbrljAfyTSdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74d7d8f1-bf2d-4a15-84bb-046f778ba15d"
      },
      "source": [
        "model_4_preds = tf.argmax(model_4.predict(val_dataset),axis=1)\n",
        "model_4_preds[:10]"
      ],
      "execution_count": 391,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([1, 1, 3, 2, 2, 4, 4, 2, 3, 3])>"
            ]
          },
          "metadata": {},
          "execution_count": 391
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3icqbm-TY2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77142aa9-adfa-41e7-adf5-e4b6cf7c5805"
      },
      "source": [
        "logging.warning(\"Evaluate metrics \")\n",
        "model_4_results = evaluation_metrics(val_labels,\n",
        "                                     model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": 392,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9664429530201343,\n",
              " 'f1': 0.9667219285451137,\n",
              " 'precision': 0.967597372798715,\n",
              " 'recall': 0.9664429530201343}"
            ]
          },
          "metadata": {},
          "execution_count": 392
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3NV-ESrTtpQ"
      },
      "source": [
        "logging.warning(\"-\"*100)\n",
        "logging.warning(\"Model 5 Bidirectional LSTM\")\n"
      ],
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsPDUQLMUJ4U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c0f5d95-1a7f-4eed-da9f-0b636c270a24"
      },
      "source": [
        "# Set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "\n",
        "# Build model\n",
        "inputs = tf.keras.Input(shape=(1,),dtype=tf.string,ragged=True)\n",
        "text_vectorization_layer = text_vectorizer(inputs)\n",
        "embedding_layer = embedding(text_vectorization_layer)\n",
        "x = layers.Bidirectional(layers.LSTM(64,return_sequences=True))(embedding_layer)\n",
        "x = layers.Bidirectional(layers.LSTM(128,return_sequences=True))(x)\n",
        "x = layers.Dense(128,activation='relu')(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(num_classes,activation='softmax')(x)\n",
        "model_5 = tf.keras.Model(inputs,outputs,name='model_5')\n",
        "\n",
        "# Compile\n",
        "model_5.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Summary\n",
        "model_5.summary()"
      ],
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_16 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_2 (TextV  (None, 714)              0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 714, 128)          3187840   \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirectio  (None, 714, 128)         98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirectio  (None, 714, 256)         263168    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 714, 128)          32896     \n",
            "                                                                 \n",
            " global_average_pooling1d_15  (None, 128)              0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,583,365\n",
            "Trainable params: 3,583,365\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFSiKlwuXghQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72123b8f-64be-4118-ce13-95994ad3527d"
      },
      "source": [
        "logging.warning(\"Fit and train model\")\n",
        "history_5 = model_5.fit(train_dataset,\n",
        "                        epochs=5,\n",
        "                        validation_data=val_dataset,\n",
        "                        callbacks=[early_stopping_callback,\n",
        "                                   create_tensorboard_callback('Model_logs',\n",
        "                                                               'Model_5_Bidirectional(LSTM)')])"
      ],
      "execution_count": 395,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: Model_logs/Model_5_Bidirectional(LSTM)/20211128-031202\n",
            "Epoch 1/5\n",
            "38/38 [==============================] - 30s 501ms/step - loss: 0.5328 - accuracy: 0.8582 - val_loss: 0.3793 - val_accuracy: 0.9027\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 17s 444ms/step - loss: 0.0786 - accuracy: 0.9832 - val_loss: 0.2854 - val_accuracy: 0.9396\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 17s 445ms/step - loss: 0.0358 - accuracy: 0.9891 - val_loss: 0.1813 - val_accuracy: 0.9530\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 17s 442ms/step - loss: 0.0124 - accuracy: 0.9983 - val_loss: 0.3922 - val_accuracy: 0.9128\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 17s 445ms/step - loss: 0.0150 - accuracy: 0.9966 - val_loss: 0.1213 - val_accuracy: 0.9597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCl4dOgkX0bn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac42ce0-9b27-457a-b791-5da8a16aaf5a"
      },
      "source": [
        "logging.warning(\"Evaluate model_5 on val_dataset\")\n",
        "model_5.evaluate(val_dataset)"
      ],
      "execution_count": 396,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 2s 150ms/step - loss: 0.1213 - accuracy: 0.9597\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.1213318333029747, 0.9597315192222595]"
            ]
          },
          "metadata": {},
          "execution_count": 396
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zODddJaYly1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a47e362-7d89-46af-a5d8-64e6b0e6c472"
      },
      "source": [
        "logging.warning(\"Make prediction using Model_5 on val_dataset\")\n",
        "model_5_preds = tf.argmax(model_5.predict(val_dataset),axis=1)\n",
        "model_5_preds"
      ],
      "execution_count": 397,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(298,), dtype=int64, numpy=\n",
              "array([1, 1, 3, 2, 2, 4, 4, 0, 3, 3, 1, 3, 3, 3, 1, 1, 2, 3, 0, 1, 3, 0,\n",
              "       0, 4, 3, 3, 1, 0, 3, 3, 2, 3, 1, 0, 0, 0, 2, 0, 0, 1, 3, 1, 4, 1,\n",
              "       4, 3, 3, 0, 3, 3, 0, 0, 0, 1, 3, 0, 3, 4, 2, 3, 3, 2, 0, 0, 4, 2,\n",
              "       4, 3, 2, 0, 2, 4, 3, 3, 4, 2, 1, 0, 1, 0, 3, 2, 0, 4, 2, 3, 0, 0,\n",
              "       0, 1, 1, 1, 3, 4, 4, 0, 4, 3, 2, 0, 0, 2, 3, 1, 1, 0, 2, 1, 1, 4,\n",
              "       3, 2, 3, 3, 0, 0, 1, 4, 0, 1, 4, 0, 0, 1, 1, 4, 3, 2, 3, 0, 2, 3,\n",
              "       3, 2, 2, 0, 4, 3, 4, 4, 3, 3, 4, 1, 4, 1, 3, 0, 0, 1, 3, 0, 3, 3,\n",
              "       1, 1, 0, 1, 2, 1, 1, 2, 3, 1, 0, 2, 4, 2, 0, 0, 2, 0, 3, 2, 4, 1,\n",
              "       0, 4, 0, 0, 4, 4, 4, 2, 2, 3, 4, 4, 4, 0, 1, 0, 2, 0, 1, 0, 0, 0,\n",
              "       2, 3, 0, 3, 2, 4, 0, 0, 4, 1, 0, 0, 3, 4, 2, 2, 3, 0, 0, 1, 4, 4,\n",
              "       0, 3, 1, 4, 1, 0, 3, 2, 2, 0, 4, 1, 2, 1, 4, 2, 1, 1, 2, 3, 0, 0,\n",
              "       3, 4, 3, 1, 4, 4, 3, 3, 3, 1, 4, 3, 1, 1, 4, 3, 0, 4, 0, 0, 1, 2,\n",
              "       0, 2, 2, 4, 0, 0, 3, 1, 4, 2, 3, 3, 4, 3, 0, 0, 2, 0, 0, 2, 0, 3,\n",
              "       1, 3, 1, 0, 3, 3, 2, 0, 0, 0, 4, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 397
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDLNlJ65Y0fH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bf8be19-5d8a-478f-d5f1-82b99adda50d"
      },
      "source": [
        "logging.warning(\"Evaluation Metrics\")\n",
        "model_5_results = evaluation_metrics(val_labels,\n",
        "                                     model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.959731543624161,\n",
              " 'f1': 0.9597354813800449,\n",
              " 'precision': 0.9630294069268686,\n",
              " 'recall': 0.959731543624161}"
            ]
          },
          "metadata": {},
          "execution_count": 398
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfUaWlPAZALP"
      },
      "source": [
        "logging.warning(\"-\"*100)\n",
        "logging.warning(\"Model 6 using Transfer Learning\")"
      ],
      "execution_count": 399,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vsMnDDm5Zhwg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d2d223-7dd9-4b5a-c921-f5ae3859f294"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 400,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.12.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.1.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heFaNGKDhmAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0e3089c-3ad9-47b6-e779-65ccc2d59363"
      },
      "source": [
        "!pip install tensorflow_text"
      ],
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow_text in /usr/local/lib/python3.7/dist-packages (2.7.3)\n",
            "Requirement already satisfied: tensorflow<2.8,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.15.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.42.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.10.0.2)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (2.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.37.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.17.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.12.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.22.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (12.0.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.6.3)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow<2.8,>=2.7.0->tensorflow_text) (1.13.3)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.3.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow<2.8,>=2.7.0->tensorflow_text) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrnwyp4bkFnQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "401bdcd3-bb5f-4ce4-dca9-514556832dc3"
      },
      "source": [
        "# Load libraries\n",
        "import tensorflow_text as text\n",
        "import tensorflow_hub as hub \n",
        "\n",
        "preprocessing_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
        "                                     trainable=False,name='preprocessing_layer')\n",
        "\n",
        "bert_layer = hub.KerasLayer('https://tfhub.dev/google/experts/bert/pubmed/2',\n",
        "                            trainable=False,\n",
        "                            name='bert_model_layer')\n",
        "# set random seed\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Creating a model out of it \n",
        "input = layers.Input(shape = [] , dtype = tf.string ,ragged=True, name = 'input_sentences')\n",
        "bert_inputs = preprocessing_layer(input)\n",
        "bert_embedding =bert_layer(bert_inputs)\n",
        "print(f'bert embedding shape: {bert_embedding}')\n",
        "x = layers.Dense(128 , activation = 'relu')(bert_embedding['pooled_output'])\n",
        "x = layers.Dropout(0.5)(x)\n",
        "output = layers.Dense(len(class_names) , activation= 'softmax')(x)\n",
        "\n",
        "# Packing into a model\n",
        "model_6 = tf.keras.Model(input , output)\n",
        "model_6.summary()"
      ],
      "execution_count": 402,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert embedding shape: {'pooled_output': <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'bert_model_layer')>, 'encoder_outputs': [<KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>], 'sequence_output': <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_model_layer')>, 'default': <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'bert_model_layer')>}\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_sentences (InputLayer)   [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " preprocessing_layer (KerasLaye  {'input_type_ids':   0          ['input_sentences[0][0]']        \n",
            " r)                             (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " bert_model_layer (KerasLayer)  {'pooled_output': (  109482241   ['preprocessing_layer[0][0]',    \n",
            "                                None, 768),                       'preprocessing_layer[0][1]',    \n",
            "                                 'encoder_outputs':               'preprocessing_layer[0][2]']    \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 'default': (None,                                                \n",
            "                                768)}                                                             \n",
            "                                                                                                  \n",
            " dense_29 (Dense)               (None, 128)          98432       ['bert_model_layer[0][13]']      \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 128)          0           ['dense_29[0][0]']               \n",
            "                                                                                                  \n",
            " dense_30 (Dense)               (None, 5)            645         ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,581,318\n",
            "Trainable params: 99,077\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxY8iz6glMYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c39a529-2d80-4fb1-9ca6-c0e6e37af05a"
      },
      "source": [
        "# Compile\n",
        "model_6.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "logging.warning(\"Fit and train\")\n",
        "history_6 = model_6.fit(train_dataset,\n",
        "                        epochs=5,\n",
        "                        validation_data=val_dataset,\n",
        "                        callbacks=[early_stopping_callback,\n",
        "                                   create_tensorboard_callback('Model_logs',\n",
        "                                                               'Model_6_Bert')])"
      ],
      "execution_count": 403,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: Model_logs/Model_6_Bert/20211128-031425\n",
            "Epoch 1/5\n",
            "38/38 [==============================] - 44s 847ms/step - loss: 1.5812 - accuracy: 0.3263 - val_loss: 1.1949 - val_accuracy: 0.6309\n",
            "Epoch 2/5\n",
            "38/38 [==============================] - 31s 818ms/step - loss: 1.1142 - accuracy: 0.5705 - val_loss: 0.8930 - val_accuracy: 0.7383\n",
            "Epoch 3/5\n",
            "38/38 [==============================] - 31s 820ms/step - loss: 0.9271 - accuracy: 0.6644 - val_loss: 0.7665 - val_accuracy: 0.7752\n",
            "Epoch 4/5\n",
            "38/38 [==============================] - 31s 822ms/step - loss: 0.7762 - accuracy: 0.7299 - val_loss: 0.6632 - val_accuracy: 0.7953\n",
            "Epoch 5/5\n",
            "38/38 [==============================] - 31s 820ms/step - loss: 0.6903 - accuracy: 0.7693 - val_loss: 0.6278 - val_accuracy: 0.8087\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTDWoef0l-Ga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba34616f-8bd1-42a4-ea06-e51191b8a8ea"
      },
      "source": [
        "logging.warning(\"Evaluate model_6 on val_dataset\")\n",
        "model_6.evaluate(val_dataset)"
      ],
      "execution_count": 404,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 6s 616ms/step - loss: 0.6278 - accuracy: 0.8087\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6278420090675354, 0.8087248206138611]"
            ]
          },
          "metadata": {},
          "execution_count": 404
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84JINlASplV3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65a0432a-15dc-4348-b341-379afad99f61"
      },
      "source": [
        "logging.warning(\"Make Prediction using model_6 on val_dataset\")\n",
        "model_6_preds = tf.argmax(model_6.predict(val_dataset),axis=1)\n",
        "model_6_preds"
      ],
      "execution_count": 405,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(298,), dtype=int64, numpy=\n",
              "array([1, 1, 3, 2, 2, 4, 4, 0, 3, 1, 1, 3, 3, 3, 1, 1, 2, 3, 0, 1, 3, 0,\n",
              "       0, 4, 3, 3, 1, 2, 3, 3, 2, 3, 3, 0, 0, 0, 2, 0, 0, 3, 1, 4, 4, 1,\n",
              "       4, 3, 3, 0, 3, 3, 0, 0, 0, 4, 3, 0, 3, 4, 2, 3, 3, 2, 3, 4, 4, 2,\n",
              "       4, 3, 2, 0, 2, 4, 3, 3, 2, 2, 3, 0, 0, 0, 3, 2, 2, 4, 1, 3, 0, 0,\n",
              "       0, 1, 4, 1, 3, 4, 4, 2, 4, 3, 2, 2, 2, 0, 3, 4, 1, 4, 2, 1, 1, 4,\n",
              "       3, 2, 1, 3, 4, 0, 1, 4, 2, 1, 4, 0, 0, 1, 4, 4, 3, 2, 3, 0, 2, 3,\n",
              "       3, 0, 2, 3, 4, 3, 0, 0, 3, 3, 0, 3, 4, 1, 1, 0, 0, 4, 3, 0, 3, 3,\n",
              "       1, 1, 0, 1, 2, 1, 3, 2, 3, 2, 0, 2, 4, 2, 0, 1, 2, 0, 2, 2, 4, 1,\n",
              "       0, 4, 0, 0, 4, 4, 4, 2, 3, 3, 4, 4, 4, 0, 1, 0, 2, 0, 1, 0, 2, 0,\n",
              "       2, 3, 0, 3, 2, 4, 0, 2, 4, 1, 0, 2, 3, 0, 2, 2, 3, 0, 0, 3, 4, 4,\n",
              "       0, 3, 1, 4, 1, 2, 3, 2, 2, 0, 4, 1, 2, 4, 4, 2, 3, 1, 2, 2, 0, 0,\n",
              "       0, 4, 3, 0, 4, 4, 3, 3, 3, 1, 4, 0, 1, 1, 0, 3, 0, 4, 0, 0, 2, 2,\n",
              "       0, 2, 2, 4, 0, 0, 3, 3, 4, 0, 3, 3, 4, 3, 0, 0, 2, 0, 0, 2, 0, 3,\n",
              "       1, 3, 1, 0, 3, 3, 2, 0, 0, 4, 4, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 405
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwZH_-lepzhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99f3fda9-09b5-44b6-8bea-376e31417a30"
      },
      "source": [
        "# Evaluation metrics\n",
        "logging.warning(\"Evaluation metrics\")\n",
        "model_6_results = evaluation_metrics(val_labels,\n",
        "                                     model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8087248322147651,\n",
              " 'f1': 0.8065580510398471,\n",
              " 'precision': 0.8117052929265929,\n",
              " 'recall': 0.8087248322147651}"
            ]
          },
          "metadata": {},
          "execution_count": 406
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G79-y4bUq0n2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "6da9f7db-94d8-4d90-f18b-150d0e31ad5b"
      },
      "source": [
        "# Combine model results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"Baseline\": baseline_results,\n",
        "                                  \"Simple_dense\": model_1_results,\n",
        "                                  \"Conv1D\": model_2_results,\n",
        "                                  \"LSTM\": model_3_results,\n",
        "                                  \"GRU\": model_4_results,\n",
        "                                  \"Bidirectional\": model_5_results,\n",
        "                                  \"BERT\": model_6_results,\n",
        "                                  })\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": 407,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Baseline</th>\n",
              "      <td>0.936242</td>\n",
              "      <td>0.940139</td>\n",
              "      <td>0.936242</td>\n",
              "      <td>0.935590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Simple_dense</th>\n",
              "      <td>0.738255</td>\n",
              "      <td>0.803972</td>\n",
              "      <td>0.738255</td>\n",
              "      <td>0.703104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Conv1D</th>\n",
              "      <td>0.956376</td>\n",
              "      <td>0.957100</td>\n",
              "      <td>0.956376</td>\n",
              "      <td>0.956023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTM</th>\n",
              "      <td>0.949664</td>\n",
              "      <td>0.952329</td>\n",
              "      <td>0.949664</td>\n",
              "      <td>0.949701</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GRU</th>\n",
              "      <td>0.966443</td>\n",
              "      <td>0.967597</td>\n",
              "      <td>0.966443</td>\n",
              "      <td>0.966722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Bidirectional</th>\n",
              "      <td>0.959732</td>\n",
              "      <td>0.963029</td>\n",
              "      <td>0.959732</td>\n",
              "      <td>0.959735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BERT</th>\n",
              "      <td>0.808725</td>\n",
              "      <td>0.811705</td>\n",
              "      <td>0.808725</td>\n",
              "      <td>0.806558</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               accuracy  precision    recall        f1\n",
              "Baseline       0.936242   0.940139  0.936242  0.935590\n",
              "Simple_dense   0.738255   0.803972  0.738255  0.703104\n",
              "Conv1D         0.956376   0.957100  0.956376  0.956023\n",
              "LSTM           0.949664   0.952329  0.949664  0.949701\n",
              "GRU            0.966443   0.967597  0.966443  0.966722\n",
              "Bidirectional  0.959732   0.963029  0.959732  0.959735\n",
              "BERT           0.808725   0.811705  0.808725  0.806558"
            ]
          },
          "metadata": {},
          "execution_count": 407
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXkiHWnfsIWL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "db22a59b-4ae1-459a-b756-2ab9febf17c7"
      },
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\", figsize=(10, 7)).legend(bbox_to_anchor=(1.0, 1.0));"
      ],
      "execution_count": 408,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSnxJBGYsKzL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "outputId": "d25d2374-28dd-4115-d353-a83f0d19e55f"
      },
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10, 7),color='lightgreen');"
      ],
      "execution_count": 409,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl51yx6bsg2H"
      },
      "source": [
        "logging.warning(\"-\"*100)"
      ],
      "execution_count": 410,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsuWEFt6S-op"
      },
      "source": [
        "logging.warning(\"Save best performing model\")"
      ],
      "execution_count": 411,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CAEYzVSbwK1",
        "outputId": "a4e9ab83-a1c8-494c-ada2-bee765490543"
      },
      "source": [
        "model_4.save('GRU Model')"
      ],
      "execution_count": 412,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: GRU Model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbRpDZfigTVC",
        "outputId": "6cbe6dbd-c14f-4f68-bad0-0b5b4299a3f4"
      },
      "source": [
        "import pickle\n",
        "pickle.dump(model_4, open('gru.pkl','wb'))\n",
        "\n",
        "# load_model\n",
        "load_pickle_model = pickle.load(open('gru.pkl','rb'))"
      ],
      "execution_count": 413,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: ram://bd6b39bf-5374-4641-ad4d-ada919ffba31/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dH3BgHZ0kXrX",
        "outputId": "f2eddd59-39ff-4508-81fb-fa1c05534de0"
      },
      "source": [
        "load_pickle_model.summary()"
      ],
      "execution_count": 422,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_GRU\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_2 (TextV  (None, None)             0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, None, 128)         3187840   \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, None, 64)          37248     \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, None, 128)         8320      \n",
            "                                                                 \n",
            " global_average_pooling1d_14  (None, 128)              0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 5)                 645       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,234,053\n",
            "Trainable params: 3,234,053\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bSvGAG4kuzY",
        "outputId": "446c6d13-0db7-4a10-95f8-000d3e10f203"
      },
      "source": [
        "load_pickle_model.evaluate(val_dataset)"
      ],
      "execution_count": 423,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 6s 596ms/step - loss: 0.1339 - accuracy: 0.9597\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.13385872542858124, 0.9597315192222595]"
            ]
          },
          "metadata": {},
          "execution_count": 423
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRaJkHomkLOQ",
        "outputId": "36437c82-74cc-4c89-de5f-8b0ea94d3034"
      },
      "source": [
        "# make prediction using saved_model\n",
        "pred_proba = load_pickle_model.predict(val_dataset)\n",
        "preds = tf.argmax(pred_proba, axis=1)\n",
        "preds"
      ],
      "execution_count": 425,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(298,), dtype=int64, numpy=\n",
              "array([1, 1, 3, 2, 2, 4, 4, 2, 3, 3, 1, 3, 3, 3, 1, 1, 2, 3, 0, 1, 3, 0,\n",
              "       0, 4, 3, 3, 1, 2, 3, 3, 2, 3, 1, 0, 0, 0, 2, 0, 0, 1, 3, 1, 4, 4,\n",
              "       4, 3, 3, 0, 3, 3, 0, 0, 0, 1, 3, 0, 3, 4, 2, 3, 3, 2, 0, 4, 4, 2,\n",
              "       4, 3, 2, 0, 2, 4, 3, 3, 4, 2, 1, 0, 1, 0, 3, 2, 0, 4, 2, 3, 0, 0,\n",
              "       0, 1, 1, 1, 3, 4, 4, 0, 4, 3, 2, 2, 0, 2, 3, 1, 1, 0, 2, 1, 1, 4,\n",
              "       3, 2, 3, 3, 0, 0, 1, 4, 4, 1, 4, 0, 0, 1, 1, 4, 3, 2, 3, 0, 2, 3,\n",
              "       3, 2, 2, 0, 4, 3, 4, 4, 3, 3, 4, 1, 4, 1, 1, 0, 2, 1, 3, 4, 3, 3,\n",
              "       1, 1, 0, 1, 2, 1, 1, 2, 3, 1, 0, 2, 4, 2, 0, 4, 2, 0, 3, 2, 4, 1,\n",
              "       0, 4, 0, 0, 4, 4, 4, 2, 2, 3, 4, 4, 4, 0, 1, 0, 2, 0, 1, 0, 0, 0,\n",
              "       2, 3, 0, 3, 2, 4, 0, 0, 4, 1, 0, 0, 3, 4, 2, 2, 3, 4, 0, 1, 4, 4,\n",
              "       0, 3, 1, 4, 1, 0, 3, 2, 2, 0, 4, 1, 2, 1, 4, 2, 1, 1, 2, 3, 0, 0,\n",
              "       3, 4, 3, 1, 4, 4, 3, 3, 3, 1, 4, 3, 1, 1, 4, 3, 0, 4, 0, 0, 1, 2,\n",
              "       0, 2, 2, 4, 0, 0, 3, 1, 4, 2, 3, 3, 4, 3, 0, 0, 2, 0, 2, 2, 0, 3,\n",
              "       1, 3, 1, 0, 3, 3, 2, 0, 0, 0, 4, 2])>"
            ]
          },
          "metadata": {},
          "execution_count": 425
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOolbp27YivR"
      },
      "source": [
        "# !tensorboard dev upload --logdir Model_logs \\\n",
        "#   --name \"News Classification Models\" \\\n",
        "#   --description \"Training results for different models\" \\\n",
        "#   --one_shot"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QRWKbiK0n7U"
      },
      "source": [
        "# !tensorboard dev list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6DFg4tS1f_i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}